# Physical Climate Risk Assessment ProcessPrompt Template v2.2

**Version**: 2.2  
**Date**: November 2025  
**Framework Version**: 2.0 (44 measures across 9 categories)  
**Purpose**: Standalone, reproducible prompt for conducting comprehensive physical climate risk assessments

---

## DOCUMENT OVERVIEW

This ProcessPrompt Template provides a **complete, standalone methodology** for assessing how companies manage physical climate risks. It can be copied into any new Manus chat or used by any analyst to conduct assessments with **identical structure, logic, and rigor**.

**Key Features of v2.2**:
- ✅ **Expanded measure definitions** with precise scoring criteria (30,000+ words of guidance)
- ✅ **Mandatory measure name standardization** (exact names required, no variations)
- ✅ **Hazard-agnostic crisis management** (M22-M26 accept comprehensive processes)
- ✅ **Enhanced completeness checks** (all 44 measures required, explicit validation)
- ✅ **Quality validation requirements** (evidence specificity, no duplication, realistic scoring)
- ✅ **Consistent categories** (9 standardized categories, no variations)

---

## TABLE OF CONTENTS

1. [Objective](#objective)
2. [Scope](#scope)
3. [Instructions for Execution](#instructions-for-execution)
4. [Input Format](#input-format)
5. [Output Format](#output-format)
6. [Scoring Framework](#scoring-framework)
7. [Expanded Measure Definitions](#expanded-measure-definitions)
8. [Verification Logic](#verification-logic)
9. [Governance Tags](#governance-tags)
10. [Quality Standards](#quality-standards)
11. [Common Pitfalls](#common-pitfalls)
12. [Continuous Improvement](#continuous-improvement)

---

## OBJECTIVE

### Purpose Statement

This workflow assesses **how companies manage physical climate risks** - the direct impacts of climate change on operations, assets, and supply chains. Physical climate risks include:

- **Acute risks**: Extreme weather events (floods, storms, hurricanes, wildfires, heatwaves, droughts)
- **Chronic risks**: Long-term shifts (sea level rise, temperature changes, precipitation patterns)

The assessment evaluates **44 specific measures** across **9 categories** of physical climate risk management, from governance and risk identification to crisis management and performance metrics.

### What This Assessment IS

✅ **Physical climate risk management**: How companies identify, assess, and manage physical climate hazards  
✅ **Adaptation and resilience**: Measures to protect operations from climate impacts  
✅ **Evidence-based**: Scores must be supported by verbatim quotes from source documents  
✅ **Realistic**: Expects imperfect disclosure and realistic maturity levels  
✅ **Comprehensive**: All 44 measures assessed for every company  

### What This Assessment is NOT

❌ **NOT emissions or transition risk**: Does not assess GHG emissions, net zero targets, or decarbonization  
❌ **NOT climate mitigation**: Does not assess efforts to reduce climate change  
❌ **NOT ESG ratings**: Focused solely on physical climate risk, not broader ESG  
❌ **NOT perfect**: Acknowledges data limitations and disclosure gaps  

---

## SCOPE

### Assessment Framework

**Framework Version**: 2.0  
**Total Measures**: 44  
**Categories**: 9  
**Scoring Scale**: 0-5 for each measure  
**Maximum Score**: 220 points (44 measures × 5 points)  

### The 9 Categories

1. **Governance & Strategic Oversight** (M01-M07) - 7 measures
   - Board oversight, management responsibility, ERM integration, commitments, scenario analysis, stakeholder engagement, policy advocacy

2. **Risk Identification & Assessment** (M08-M16) - 9 measures
   - Hazard identification, asset exposure, vulnerability assessment, scenario modeling, financial quantification, supply chain assessment, validation, compliance, disclosure quality

3. **Asset Design & Resilience** (M17-M21) - 5 measures
   - Resilient design standards, retrofitting programs, nature-based solutions, critical infrastructure protection, relocation/divestment

4. **Crisis Management** (M22-M26) - 5 measures
   - Business continuity plans, emergency response protocols, crisis communication systems, recovery time objectives, post-event review

5. **Supply Chain Management** (M27-M31) - 5 measures
   - Supplier assessment, diversification, contractual provisions, inventory management, logistics flexibility

6. **Insurance & Risk Transfer** (M32-M35) - 4 measures
   - Coverage adequacy, parametric insurance, captives/self-insurance, claims management

7. **Data Quality & Assurance** (M36-M37) - 2 measures
   - Data governance, external assurance

8. **Workforce & Community** (M38-M40) - 3 measures
   - Employee safety, community engagement, just transition

9. **KPIs & Outcomes** (M41-M44) - 4 measures
   - Downtime metrics, financial impact disclosure, supplier disruption metrics, adaptation spend

### Coverage Requirements

**Geographic**: Global operations (headquarters, subsidiaries, joint ventures where material)  
**Temporal**: Current practices (most recent 1-3 years)  
**Materiality**: Focus on material operations (≥50% of revenue, assets, or employees)  

---

## INSTRUCTIONS FOR EXECUTION

### Overview: 4-Phase Sequential Workflow

This assessment follows a **mandatory 4-phase sequence**. Do not skip phases or change the order.

**Phase 1**: Company Identification & Document Discovery (10-15 minutes)  
**Phase 2**: Comprehensive Information Gathering (15-25 minutes)  
**Phase 3**: Measure-by-Measure Assessment (10-15 minutes)  
**Phase 4**: Quality Validation & Output (5 minutes)  

**Total Time**: 40-60 minutes per company

---

### PHASE 1: Company Identification & Document Discovery

**Objective**: Locate and access all relevant disclosure documents for the company.

**Steps**:

1. **Verify Company Identity**
   - Confirm company name, ISIN, sector, country
   - Identify headquarters location
   - Determine primary business activities

2. **Search SustainabilityReports.com FIRST** (Mandatory)
   - Navigate to https://www.sustainabilityreports.com/
   - Search by company name or ISIN
   - Download all available reports (sustainability, climate, ESG, annual reports)
   - Note: Free tier allows 5 PDF downloads per day
   - This is the **primary source** - check here before company website

3. **Search Company Website** (Secondary)
   - Navigate to company investor relations page
   - Look for: Sustainability Reports, Climate Reports, ESG Reports, Annual Reports, CDP disclosures
   - Download all relevant documents (typically 2-5 documents)
   - Check for: "Sustainability", "ESG", "Climate", "Environment", "Responsibility"

4. **Web Search for Additional Sources** (Tertiary)
   - Search: `[Company Name] climate risk assessment`
   - Search: `[Company Name] physical climate risk`
   - Search: `[Company Name] CDP climate change response`
   - Look for: Press releases, case studies, third-party reports

5. **Document Inventory**
   - List all documents found (title, year, page count, URL)
   - Prioritize: Most recent (2023-2025) and most comprehensive
   - Typical sources:
     * Sustainability Report (primary)
     * Climate Action Report or TCFD Report (primary)
     * Annual Report (secondary - usually limited climate info)
     * CDP Climate Change Response (primary if available)
     * Investor presentations (tertiary)

**Quality Check**:
- ✅ At least 2 primary sources found (sustainability + climate reports)
- ✅ Most recent reports (2023-2025)
- ✅ SustainabilityReports.com checked first
- ✅ Company website checked as backup
- ✅ Web search conducted for additional sources

**Time**: 10-15 minutes

---

### PHASE 2: Comprehensive Information Gathering

**Objective**: Extract all relevant information about physical climate risk management from discovered documents.

**Steps**:

1. **Read Documents Systematically**
   - Start with most recent sustainability/climate report
   - Read sections on: Climate Risk, Physical Risk, Risk Management, Resilience, Adaptation
   - Note page numbers for all relevant information
   - Create evidence notes file with verbatim quotes

2. **Search for Specific Topics** (Use document search/Ctrl+F)
   - "Physical risk" or "physical climate risk"
   - "Extreme weather" or "natural disasters"
   - "Floods" / "Storms" / "Heat" / "Wildfire" / "Drought" / "Sea level"
   - "Business continuity" / "Emergency response"
   - "Climate scenario" / "Climate modeling"
   - "Adaptation" / "Resilience"
   - "TCFD" (Task Force on Climate-related Financial Disclosures)

3. **Extract Evidence for Each Category**
   - **Governance**: Board oversight, management roles, committees
   - **Risk Assessment**: Hazards identified, assets assessed, scenario analysis
   - **Adaptation**: Design standards, retrofitting, nature-based solutions
   - **Crisis Management**: BCPs, emergency protocols, communication systems
   - **Supply Chain**: Supplier assessment, diversification
   - **Insurance**: Coverage, parametric products
   - **Data**: Governance, assurance
   - **Workforce**: Employee safety, community engagement
   - **KPIs**: Metrics, financial impacts, adaptation spend

4. **Record Evidence with Precision**
   - Copy verbatim quotes (exact text, no paraphrasing)
   - Note source document, page number, section
   - Include context (what the quote is describing)
   - Flag any quantitative data (percentages, dollar amounts, counts)

5. **Identify Gaps**
   - Note which measures have NO evidence
   - Note which measures have LIMITED evidence
   - This will inform scoring (no evidence = score 0)

**Quality Check**:
- ✅ All documents reviewed systematically
- ✅ Evidence extracted for at least 30/44 measures (68%+ coverage expected)
- ✅ All evidence includes verbatim quotes
- ✅ All evidence includes source and page number
- ✅ Gaps identified and documented

**Time**: 15-25 minutes

---

### PHASE 3: Measure-by-Measure Assessment

**Objective**: Assess the company against all 44 measures using the expanded definitions and scoring criteria.

**Critical Requirements**:

1. **USE EXACT MEASURE NAMES** (Mandatory)
   - Copy measure names from the Standard Measure Names Reference (Section 7)
   - Do NOT paraphrase, abbreviate, or modify measure names
   - Do NOT create your own measure names
   - Validation will reject any assessment with non-standard names

2. **USE EXACT CATEGORY NAMES** (Mandatory)
   - Copy category names from the Standard Measure Names Reference (Section 7)
   - Do NOT paraphrase or modify category names
   - Each measure MUST use its designated category

3. **ASSESS ALL 44 MEASURES** (Mandatory)
   - Do NOT skip any measures
   - If no evidence found, score = 0 (do not omit the measure)
   - Validation will reject any assessment with <44 measures

4. **FOLLOW EXPANDED DEFINITIONS** (Mandatory)
   - Read the expanded definition for each measure (Section 7)
   - Apply the specific scoring criteria for that measure
   - Check "What MUST be present" and "What does NOT qualify"
   - Use the score level examples as guidance

**Steps for Each Measure**:

1. **Read Expanded Definition**
   - Understand what the measure assesses
   - Note mandatory requirements for high scores
   - Note explicit exclusions

2. **Review Evidence**
   - Check evidence notes from Phase 2
   - Identify all relevant quotes for this measure
   - Assess evidence quality and specificity

3. **Apply Scoring Criteria**
   - Match evidence against score level descriptions (0-5)
   - Check coverage requirements (e.g., ≥50% for score 3)
   - Check frequency requirements (e.g., annual for score 3)
   - Be realistic - most companies score 2-3, not 4-5

4. **Write Rationale** (200-400 words)
   - Explain WHY this score was assigned
   - Reference specific evidence
   - Note what is present and what is missing
   - Be specific about coverage, frequency, documentation

5. **Extract Evidence** (Verbatim)
   - Copy exact quotes from source documents
   - Include multiple quotes if available (separate with " | ")
   - Do NOT paraphrase or summarize
   - If no evidence, leave blank (score will be 0)

6. **Record Source**
   - Document title, page number, URL
   - Use format: "Document Title, p. X | Document Title, p. Y"
   - Separate multiple sources with " | "

7. **Assign Confidence**
   - **High**: Strong, specific evidence with quantitative data
   - **Medium**: General evidence without quantification
   - **Low**: Implied or indirect evidence

**Special Considerations**:

**For M22-M26 (Crisis Management)**:
- These measures are **hazard-agnostic**
- Comprehensive BCPs, emergency protocols, crisis communication, RTOs, and post-event reviews do NOT need to explicitly mention "physical climate risks"
- If processes are comprehensive enough to address the disruption types caused by physical climate events, they qualify
- Example: "We have comprehensive business continuity plans covering facility damage, power outages, supply chain disruption, employee safety, and IT systems" → This qualifies even without mentioning "physical climate"
- See expanded definitions in Section 7 for detailed guidance

**For All Other Measures**:
- Evidence MUST explicitly address physical climate risks or specific hazards (floods, storms, heat, etc.)
- Generic "climate" or "climate change" without physical risk specificity does NOT qualify for high scores
- Example: "Board reviews climate strategy" → Score 1 (too generic)
- Example: "Board reviews physical climate risks including floods and storms quarterly" → Score 3+ (specific)

**Quality Check (After Each Measure)**:
- ✅ Measure name matches Standard Reference exactly
- ✅ Category name matches Standard Reference exactly
- ✅ Score (0-5) assigned based on expanded definition criteria
- ✅ Rationale (200-400 words) explains the score
- ✅ Evidence is verbatim (if score > 0)
- ✅ Source includes document and page number
- ✅ Confidence level assigned (High/Medium/Low)

**Time**: 10-15 minutes (20-30 seconds per measure)

---

### PHASE 4: Quality Validation & Output

**Objective**: Validate the assessment for completeness, consistency, and quality before finalizing.

**Validation Checklist**:

**1. Completeness Check (CRITICAL)**
- ✅ Exactly 44 measures assessed (no more, no fewer)
- ✅ All measures M01-M44 present
- ✅ No duplicate measure IDs
- ✅ No missing measure IDs

**2. Measure Name Standardization (CRITICAL)**
- ✅ All measure names match Standard Reference exactly
- ✅ All category names match Standard Reference exactly
- ✅ No paraphrasing or abbreviations
- ✅ No typos in measure or category names

**3. Scoring Validation**
- ✅ All scores are 0-5 (no decimals, no out-of-range scores)
- ✅ Score distribution is realistic (most scores 2-3, few 4-5)
- ✅ Scores ≥3 have strong evidence
- ✅ Scores 0-1 have weak/no evidence

**4. Evidence Quality**
- ✅ All scores >0 have verbatim evidence
- ✅ No paraphrased evidence
- ✅ Evidence is measure-specific (not generic)
- ✅ No evidence duplication across measures
- ✅ Evidence coverage ≥60% (at least 26/44 measures with evidence)

**5. Source Documentation**
- ✅ All evidence has source document
- ✅ All evidence has page number
- ✅ Source format is consistent
- ✅ URLs are valid (if included)

**6. Rationale Quality**
- ✅ All rationales are 200-400 words
- ✅ Rationales explain the score
- ✅ Rationales reference specific evidence
- ✅ Rationales note coverage and gaps

**7. Confidence Levels**
- ✅ All measures have confidence assigned
- ✅ High confidence has quantitative evidence
- ✅ Medium confidence has qualitative evidence
- ✅ Low confidence has implied/indirect evidence

**8. Physical Risk Focus**
- ✅ Evidence addresses physical climate risks (not transition risks)
- ✅ No emissions reduction evidence counted as physical risk management
- ✅ No net zero targets counted as physical risk management
- ✅ Exception: M22-M26 can be hazard-agnostic

**Validation Errors & Fixes**:

| Error | Fix |
|-------|-----|
| <44 measures | Add missing measures with score 0 |
| >44 measures | Remove duplicate measures |
| Non-standard measure name | Replace with exact name from Standard Reference |
| Non-standard category name | Replace with exact name from Standard Reference |
| Score >5 or <0 | Correct to 0-5 range |
| Evidence paraphrased | Replace with verbatim quote |
| Evidence duplicated | Find measure-specific evidence |
| No source/page number | Add source documentation |
| Rationale too short | Expand to 200-400 words |
| Transition risk evidence | Remove or replace with physical risk evidence |

**Final Output Generation**:

Once validation passes, generate the final JSON output (see Section 5 for format).

**Time**: 5 minutes

---

## INPUT FORMAT

### Required Company Data

Provide the following information for each company to be assessed:

```json
{
  "company_name": "Full legal company name",
  "isin": "12-character ISIN code",
  "sector": "Primary sector (e.g., Energy, Financials, Industrials)",
  "industry": "Specific industry (e.g., Electric Utilities, Banks, Aerospace)",
  "country": "Country of headquarters",
  "assessment_date": "YYYY-MM-DD"
}
```

### Input Validation

**Required Fields**:
- ✅ `company_name`: Non-empty string
- ✅ `isin`: 12-character alphanumeric (e.g., US0378331005)
- ✅ `sector`: One of GICS sectors
- ✅ `industry`: Specific industry within sector
- ✅ `country`: ISO country name
- ✅ `assessment_date`: ISO date format (YYYY-MM-DD)

**Example Input**:

```json
{
  "company_name": "AXA SA",
  "isin": "FR0000120628",
  "sector": "Financials",
  "industry": "Insurance",
  "country": "France",
  "assessment_date": "2025-11-05"
}
```

---

## OUTPUT FORMAT

### JSON Schema

The assessment output MUST follow this exact JSON schema:

```json
{
  "company_name": "string",
  "isin": "string",
  "sector": "string",
  "industry": "string",
  "country": "string",
  "assessment_date": "YYYY-MM-DD",
  "assessor": "string (e.g., 'Manus AI', 'Analyst Name')",
  "framework_version": "2.0",
  "total_measures": 44,
  "measures": [
    {
      "measure_id": "M01",
      "measure_name": "Board-level physical risk oversight",
      "category": "Governance & Strategic Oversight",
      "score": 3,
      "max_score": 5,
      "confidence": "High",
      "rationale": "Detailed explanation of score (200-400 words)...",
      "evidence": "Verbatim quote from source | Another verbatim quote",
      "source": "Document Title, p. X | Document Title, p. Y",
      "source_pages": "5 | 12",
      "quote_count": 2
    },
    // ... 43 more measures
  ],
  "summary": {
    "total_score": 132,
    "max_possible_score": 220,
    "score_percentage": 60.0,
    "average_score": 3.0,
    "evidence_coverage": 75.0,
    "total_quotes": 85,
    "confidence_distribution": {
      "High": 25,
      "Medium": 15,
      "Low": 4
    }
  }
}
```

### Field Definitions

**Company-Level Fields**:
- `company_name`: Full legal name
- `isin`: 12-character ISIN
- `sector`: GICS sector
- `industry`: Specific industry
- `country`: Country of headquarters
- `assessment_date`: Date assessment conducted (YYYY-MM-DD)
- `assessor`: Name of person/system conducting assessment
- `framework_version`: "2.0" (current version)
- `total_measures`: 44 (always)

**Measure-Level Fields**:
- `measure_id`: M01-M44 (sequential)
- `measure_name`: Exact name from Standard Reference (no variations)
- `category`: Exact category name from Standard Reference (no variations)
- `score`: 0-5 (integer, no decimals)
- `max_score`: 5 (always)
- `confidence`: "High" | "Medium" | "Low"
- `rationale`: 200-400 words explaining the score
- `evidence`: Verbatim quotes separated by " | " (empty string if no evidence)
- `source`: Document titles and page numbers separated by " | "
- `source_pages`: Page numbers only, separated by " | "
- `quote_count`: Number of quotes (0 if no evidence)

**Summary Fields**:
- `total_score`: Sum of all 44 scores (0-220)
- `max_possible_score`: 220 (always)
- `score_percentage`: (total_score / 220) × 100
- `average_score`: total_score / 44
- `evidence_coverage`: (measures with evidence / 44) × 100
- `total_quotes`: Sum of all quote_count values
- `confidence_distribution`: Count of High/Medium/Low confidence measures

### Evidence Formatting Rules

**Verbatim Quotes**:
- Copy exact text from source documents
- Use quotation marks if needed for clarity
- Do NOT paraphrase or summarize
- Do NOT add your own words

**Multiple Quotes**:
- Separate with " | " (space-pipe-space)
- Example: "Quote 1 from page 5 | Quote 2 from page 12"

**No Evidence**:
- Use empty string: `"evidence": ""`
- Score must be 0 if no evidence

**Source Format**:
- Format: "Document Title, p. X"
- Multiple sources: "Doc1, p. X | Doc2, p. Y"
- Example: "Sustainability Report 2024, p. 45 | Climate Action Report 2024, p. 12"

---

## SCORING FRAMEWORK

### Scoring Philosophy

**Realistic Expectations**:
- Most companies score 2-3 on most measures (emerging to moderate maturity)
- Scores of 4-5 are rare and require exceptional evidence
- Scores of 0-1 are common for measures with no/weak evidence
- Perfect scores (5/5) across all measures are virtually impossible

**Evidence-Based Scoring**:
- Scores >0 MUST have verbatim evidence
- Scores ≥3 MUST have strong, specific evidence
- No evidence = Score 0 (always)
- Implied evidence = Score 1 maximum

**Physical Risk Focus**:
- Evidence MUST address physical climate risks (floods, storms, heat, etc.)
- Generic "climate" without physical specificity = Low scores
- Emissions reduction, net zero, decarbonization = NOT physical risk (score 0)
- Exception: M22-M26 (crisis management) can be hazard-agnostic

### Score Definitions (0-5 Scale)

**Score 0: No Evidence**
- No information found
- No disclosure on this measure
- Generic mention without substance

**Score 1: Minimal / Implied**
- Generic mention without specifics
- Implied practices without documentation
- <25% coverage or ad hoc practices
- Example: "We consider climate risks"

**Score 2: Basic / Limited**
- Some documentation but limited scope
- <50% coverage
- Ad hoc or infrequent practices
- Example: "We assess physical risks at key facilities"

**Score 3: Moderate / Systematic**
- Documented practices with ≥50% coverage
- Systematic approach (at least annual)
- Multiple hazards or operations covered
- Example: "We assess physical risks at 60% of facilities annually, covering floods, storms, and heat"

**Score 4: Advanced / Comprehensive**
- Comprehensive documentation with ≥80% coverage
- Frequent practices (≥2x/year)
- Multiple hazards, time horizons, or scenarios
- Quantitative metrics or targets
- Example: "We assess physical risks at 85% of facilities semi-annually, covering 5+ hazards with scenario modeling and financial quantification"

**Score 5: Leading / Integrated**
- Group-wide (≥95%) coverage
- Fully integrated into operations and decision-making
- External validation or certification
- Real-time monitoring or advanced analytics
- Continuous improvement with documented outcomes
- Example: "We assess physical risks at 100% of facilities quarterly, covering 10+ hazards with advanced scenario modeling, financial quantification, external validation, and integration into capital allocation and risk management"

### Coverage Thresholds

Many measures use coverage thresholds (% of operations, assets, suppliers, etc.). Use these as guidance:

| Score | Coverage |
|-------|----------|
| 0 | 0% |
| 1 | <25% |
| 2 | <50% |
| 3 | ≥50% |
| 4 | ≥80% |
| 5 | ≥95% |

### Frequency Thresholds

Many measures use frequency thresholds (how often practices occur). Use these as guidance:

| Score | Frequency |
|-------|-----------|
| 0 | Never |
| 1 | Ad hoc |
| 2 | Infrequent (<annual) |
| 3 | Annual |
| 4 | Semi-annual or quarterly |
| 5 | Quarterly or more frequent |

### Expected Score Distribution

A typical company assessment should have approximately:

- **Score 0**: 20-30% of measures (9-13 measures) - No evidence
- **Score 1**: 10-20% of measures (4-9 measures) - Minimal evidence
- **Score 2**: 20-30% of measures (9-13 measures) - Basic practices
- **Score 3**: 20-30% of measures (9-13 measures) - Moderate practices
- **Score 4**: 5-15% of measures (2-7 measures) - Advanced practices
- **Score 5**: 0-5% of measures (0-2 measures) - Leading practices

**Average Score**: 2.5-3.0 (typical for mature companies with good disclosure)

If your assessment deviates significantly from this distribution, review for:
- Over-scoring (too many 4-5 scores)
- Under-scoring (too many 0-1 scores)
- Evidence quality issues
- Misinterpretation of scoring criteria

---

## EXPANDED MEASURE DEFINITIONS

### How to Use This Section

For each of the 44 measures, this section provides:

1. **Standard Name**: The exact measure name to use (copy-paste, no modifications)
2. **Expanded Definition**: What the measure assesses (200-300 words)
3. **What MUST be present for high scores**: Mandatory requirements
4. **What does NOT qualify**: Explicit exclusions
5. **Scoring Criteria**: Detailed descriptions for each score level (0-5) with examples

**CRITICAL**: Always copy-paste the Standard Name exactly. Do NOT create your own measure names.

---

### STANDARD MEASURE NAMES REFERENCE TABLE

Copy-paste measure names and categories from this table. Do NOT modify.

| Measure ID | Standard Measure Name | Standard Category Name |
|------------|-----------------------|------------------------|
| M01 | Board-level physical risk oversight | Governance & Strategic Oversight |
| M02 | Management-level responsibility | Governance & Strategic Oversight |
| M03 | Integration into enterprise risk management | Governance & Strategic Oversight |
| M04 | Commitment to physical risk management | Governance & Strategic Oversight |
| M05 | Scenario analysis & forward-looking assessment | Governance & Strategic Oversight |
| M06 | Stakeholder engagement on physical risks | Governance & Strategic Oversight |
| M07 | Policy advocacy on climate adaptation | Governance & Strategic Oversight |
| M08 | Hazard identification & prioritization | Risk Identification & Assessment |
| M09 | Asset-level exposure assessment | Risk Identification & Assessment |
| M10 | Vulnerability & sensitivity analysis | Risk Identification & Assessment |
| M11 | Scenario modeling (acute & chronic risks) | Risk Identification & Assessment |
| M12 | Financial impact quantification | Risk Identification & Assessment |
| M13 | Supply chain climate risk assessment | Risk Identification & Assessment |
| M14 | Third-party validation of risk models | Risk Identification & Assessment |
| M15 | Regulatory & legal compliance tracking | Risk Identification & Assessment |
| M16 | Disclosure quality (TCFD alignment) | Risk Identification & Assessment |
| M17 | Resilient design standards | Asset Design & Resilience |
| M18 | Retrofitting & hardening programs | Asset Design & Resilience |
| M19 | Nature-based solutions | Asset Design & Resilience |
| M20 | Critical infrastructure protection | Asset Design & Resilience |
| M21 | Relocation & divestment strategies | Asset Design & Resilience |
| M22 | Business continuity plans (BCPs) | Crisis Management |
| M23 | Emergency response protocols | Crisis Management |
| M24 | Crisis communication systems | Crisis Management |
| M25 | Recovery time objectives (RTOs) | Crisis Management |
| M26 | Post-event review & continuous improvement | Crisis Management |
| M27 | Supplier physical risk assessment | Supply Chain Management |
| M28 | Supplier diversification & redundancy | Supply Chain Management |
| M29 | Contractual provisions for climate risks | Supply Chain Management |
| M30 | Inventory & buffer stock management | Supply Chain Management |
| M31 | Logistics & transportation flexibility | Supply Chain Management |
| M32 | Insurance coverage adequacy | Insurance & Risk Transfer |
| M33 | Parametric insurance products | Insurance & Risk Transfer |
| M34 | Captives & self-insurance mechanisms | Insurance & Risk Transfer |
| M35 | Claims management & recovery | Insurance & Risk Transfer |
| M36 | Data governance & quality assurance | Data Quality & Assurance |
| M37 | External assurance of climate data | Data Quality & Assurance |
| M38 | Employee safety & health protocols | Workforce & Community |
| M39 | Community resilience & engagement | Workforce & Community |
| M40 | Just transition considerations | Workforce & Community |
| M41 | Downtime & disruption metrics | KPIs & Outcomes |
| M42 | Financial impact disclosure | KPIs & Outcomes |
| M43 | Supplier disruption metrics | KPIs & Outcomes |
| M44 | Adaptation spend & investment tracking | KPIs & Outcomes |

---

### CATEGORY 1: GOVERNANCE & STRATEGIC OVERSIGHT

[Note: Due to length constraints, I'll include the first 3 measures as examples. The full template would include all 44 measures with expanded definitions. The structure below should be replicated for all measures.]

#### M01 - Board-level physical risk oversight

**Standard Name**: `Board-level physical risk oversight`

**Expanded Definition**:
Explicit **board-level oversight** of physical climate risks, including:
- Named board committee with documented responsibility
- Review frequency (quarterly, semi-annual, annual)
- Specific hazards or time horizons covered
- Integration into board risk oversight framework
- Documentation in board charters, mandates, or governance documents

This measure assesses whether the company's highest governance body (Board of Directors or equivalent) has **explicit, documented oversight** of physical climate risks.

**What MUST be present for high scores**:
- ✅ **Explicit mention of "physical climate risk"** or equivalent terms (extreme weather, natural disasters, climate hazards, floods, storms, heat, wildfires, etc.)
- ✅ **Named board committee** (e.g., "Risk Committee", "Sustainability Committee", "Audit Committee")
- ✅ **Documented oversight responsibility** (charter, mandate, terms of reference)
- ✅ **Review frequency** stated (e.g., "quarterly", "semi-annual", "annual")
- ✅ **Specific hazards or time horizons** mentioned (e.g., "floods and storms", "acute and chronic risks")

**What does NOT qualify**:
- ❌ Generic "climate change" or "climate risk" without physical risk specificity
- ❌ "Climate strategy" or "climate transition plan" without physical risk mention
- ❌ Emissions reduction, net zero, or decarbonization oversight (transition risk, not physical)
- ❌ "ESG" or "sustainability" oversight without physical risk specificity
- ❌ Implied oversight without explicit documentation

**Scoring Criteria**:

**Score 0**: No board-level oversight of physical climate risks.

**Score 1**: Generic mention of board oversight without physical climate risk specificity.
- Example: "Board oversees climate strategy"
- Example: "Board reviews sustainability matters"
- Generic "climate" without "physical" specificity

**Score 2**: Implied or indirect board oversight; no named committee or review frequency.
- Example: "Board is informed of climate risks"
- Example: "Board receives updates on environmental matters"
- Physical risks implied but not explicitly stated

**Score 3**: Explicit board/committee oversight of physical climate risks with at least annual review; ≥50% subsidiaries covered; hazards or time horizons referenced.
- Example: "Risk Committee oversees physical climate risks including floods and storms, reviewed annually"
- Explicit physical risk mention
- Named committee
- Review frequency stated (annual minimum)
- Covers at least half of group operations

**Score 4**: Comprehensive board oversight (\u226580% subsidiaries); semi-annual or quarterly review; multiple hazards and time horizons; integration into ERM.
- Example: "Risk Committee oversees physical climate risks across 85% of operations, including acute risks (floods, storms, heat) and chronic risks (sea level rise, temperature shifts), reviewed quarterly, integrated into enterprise risk management framework"
- Broad coverage (≥80%)
- Frequent review (semi-annual or quarterly)
- Multiple hazards and time horizons
- Integration into broader risk framework

**Score 5**: Group-wide (\u226595%) board oversight with quarterly review, multi-hazard focus, external validation, and integration into strategy and capital allocation.
- Example: "Board Risk Committee oversees physical climate risks group-wide (100% of operations), covering 10+ acute and chronic hazards across multiple time horizons (2030, 2050, 2100), reviewed quarterly with external expert input, integrated into strategic planning, capital allocation, and executive compensation"
- Full group coverage
- Frequent review (quarterly or more)
- Comprehensive hazard coverage
- External validation
- Integration into strategy and compensation

**Mandatory Evidence**: Verbatim quote from governance documents, sustainability reports, or proxy statements showing board oversight of physical climate risks.

---

#### M02 - Management-level responsibility

**Standard Name**: `Management-level responsibility`

**Expanded Definition**:
Designated **management-level responsibility** for physical climate risk management, including:
- Named executive or management position
- Documented responsibilities and authority
- Reporting lines to board or CEO
- Resources allocated (team, budget)
- Integration into performance objectives or compensation

This measure assesses whether the company has assigned clear **management accountability** for physical climate risk management.

**What MUST be present for high scores**:
- ✅ **Named position** (e.g., "Chief Risk Officer", "Chief Sustainability Officer", "VP of Risk Management")
- ✅ **Documented responsibility** for physical climate risks
- ✅ **Reporting line** to board or CEO stated
- ✅ **Resources allocated** (team size, budget, or authority mentioned)
- ✅ **Integration into objectives** or compensation (for score 4+)

**What does NOT qualify**:
- ❌ Generic "management oversees climate" without named position
- ❌ Sustainability manager without physical risk responsibility
- ❌ Transition risk management only (emissions, net zero)
- ❌ No documented responsibility or reporting line

**Scoring Criteria**:

**Score 0**: No management-level responsibility for physical climate risks.

**Score 1**: Generic mention of management involvement without named position or documented responsibility.
- Example: "Management considers climate risks"
- No specific position or person named

**Score 2**: Named position with implied responsibility; no documented reporting line or resources.
- Example: "Chief Risk Officer oversees climate risks"
- Position named but limited detail on physical risk specificity or resources

**Score 3**: Named position with documented responsibility for physical climate risks; reporting line to board/CEO; ≥50% operations covered.
- Example: "Chief Risk Officer is responsible for physical climate risk management across 60% of operations, reports to Board Risk Committee quarterly"
- Named position
- Documented physical risk responsibility
- Reporting line stated
- Covers majority of operations

**Score 4**: Named position with comprehensive responsibility (\u226580% operations); dedicated team or budget; integration into performance objectives.
- Example: "Chief Risk Officer leads physical climate risk management group-wide (85% coverage), supported by a 5-person team and $2M annual budget, reports to Board quarterly, with physical risk management integrated into annual performance objectives"
- Broad coverage (≥80%)
- Resources allocated (team/budget)
- Integration into objectives

**Score 5**: Group-wide (\u226595%) management responsibility with dedicated resources, board reporting, and integration into executive compensation.
- Example: "Chief Risk Officer has group-wide responsibility for physical climate risk management (100% coverage), supported by a 10-person team and $5M annual budget, reports to Board quarterly, with physical risk KPIs integrated into executive compensation (20% weighting)"
- Full group coverage
- Significant resources
- Integration into compensation

**Mandatory Evidence**: Verbatim quote showing named position, documented responsibility, and reporting line.

---

#### M03 - Integration into enterprise risk management

**Standard Name**: `Integration into enterprise risk management`

**Expanded Definition**:
Integration of **physical climate risks into the company's enterprise risk management (ERM) framework**, including:
- Physical climate risks identified in risk register
- Risk assessment methodology applied
- Risk appetite and tolerance levels defined
- Risk mitigation and monitoring processes
- Reporting to board and senior management

This measure assesses whether physical climate risks are treated as **enterprise-level risks** alongside other strategic, operational, and financial risks.

**What MUST be present for high scores**:
- ✅ **Physical climate risks in risk register** or risk taxonomy
- ✅ **Risk assessment methodology** applied (likelihood, impact, time horizon)
- ✅ **Risk appetite/tolerance** defined for physical climate risks
- ✅ **Mitigation and monitoring** processes in place
- ✅ **Reporting** to board and senior management

**What does NOT qualify**:
- ❌ Generic "climate risks" without physical specificity
- ❌ Standalone climate risk assessment not integrated into ERM
- ❌ No risk register or formal ERM framework
- ❌ Transition risks only (emissions, carbon pricing)

**Scoring Criteria**:

**Score 0**: No integration of physical climate risks into ERM.

**Score 1**: Generic mention of climate in ERM without physical risk specificity.
- Example: "Climate change is considered in our risk management"
- No evidence of formal integration

**Score 2**: Physical climate risks identified in risk register; limited integration; <50% operations.
- Example: "Physical climate risks (floods, storms) are included in our risk register for key facilities"
- Identified but limited integration

**Score 3**: Physical climate risks integrated into ERM with risk assessment methodology; ≥50% operations; regular monitoring.
- Example: "Physical climate risks are integrated into our ERM framework, assessed using likelihood and impact methodology across 60% of operations, monitored quarterly, and reported to Risk Committee"
- Formal integration
- Methodology applied
- Regular monitoring
- Covers majority of operations

**Score 4**: Comprehensive ERM integration (\u226580% operations); risk appetite defined; mitigation plans; semi-annual or quarterly reporting.
- Example: "Physical climate risks are fully integrated into our ERM framework across 85% of operations, with defined risk appetite (e.g., <5% revenue at risk from floods), mitigation plans for high-risk sites, and quarterly reporting to Board"
- Broad coverage (≥80%)
- Risk appetite defined
- Mitigation plans in place
- Frequent reporting

**Score 5**: Group-wide (\u226595%) ERM integration with quantified risk appetite, comprehensive mitigation, real-time monitoring, and integration into strategic planning.
- Example: "Physical climate risks are integrated into our ERM framework group-wide (100% coverage), with quantified risk appetite by hazard type, comprehensive mitigation plans, real-time monitoring dashboards, and integration into strategic planning and capital allocation"
- Full group coverage
- Quantified risk appetite
- Real-time monitoring
- Integration into strategy

**Mandatory Evidence**: Verbatim quote showing physical climate risks in ERM framework, risk register, or risk management disclosures.

---

## CATEGORY 1: GOVERNANCE & STRATEGIC OVERSIGHT

### M01 - Board-level physical risk oversight

**Standard Name**: `Board-level physical risk oversight`

**Expanded Definition**:
Existence and clarity of a Board of Directors mandate, committee charter, or governance document that **explicitly assigns responsibility** for overseeing the company's exposure to and management of **physical climate risks** (acute hazards like floods, storms, wildfires, hurricanes; chronic hazards like sea level rise, heat stress, water stress, precipitation changes). This includes:
- Named board committee or full board with explicit physical risk oversight responsibility
- Documented review frequency (quarterly, semi-annual, annual)
- Scope of oversight (which hazards, which geographies, which time horizons)
- Coverage across subsidiaries and business units
- Integration with enterprise risk management and strategy

**What MUST be present for high scores**:
- ✅ **Explicit mention of "physical climate risk"** or equivalent terms (extreme weather, natural disasters, climate hazards, floods, storms, heat, wildfires, etc.)
- ✅ **Named board committee** (e.g., "Risk Committee", "Sustainability Committee", "Audit Committee")
- ✅ **Documented oversight responsibility** (charter, mandate, terms of reference)
- ✅ **Review frequency** stated (e.g., "quarterly", "semi-annual", "annual")
- ✅ **Specific hazards or time horizons** mentioned (e.g., "floods and storms", "near-term and long-term")

**What does NOT qualify**:
- ❌ Generic "climate change" or "climate risk" without physical risk specificity
- ❌ "Climate strategy" or "climate transition plan" without physical risk mention
- ❌ Emissions reduction, net zero, or decarbonization oversight (transition risk, not physical)
- ❌ "ESG" or "sustainability" oversight without physical risk specificity
- ❌ Implied oversight without explicit documentation

**Scoring Criteria**:

**Score 0**: No evidence of board-level oversight of physical climate risks.
- No mention of board involvement in physical risk
- Only mentions emissions, transition, or net zero (not physical risk)

**Score 1**: Generic mention of board oversight of "climate" without physical risk specificity.
- Example: "Board oversees climate strategy" (no mention of physical risks)
- Example: "Board reviews sustainability matters" (too generic)

**Score 2**: Board or committee mentioned but physical risk oversight not explicit; OR ad hoc review; OR <50% group coverage.
- Example: "Risk Committee reviews climate-related risks" (not explicit about physical)
- Example: "Board reviews physical risks as needed" (ad hoc, not regular)
- Example: Physical risk oversight only for certain subsidiaries or regions

**Score 3**: **Explicit** board/committee oversight of physical climate risks with at least annual review; ≥50% subsidiaries covered; hazards or time horizons referenced.
- Example: "Risk Committee oversees physical climate risks including floods and storms, reviewed annually"
- Must explicitly mention physical risks (not just "climate")
- Must state review frequency (annual minimum)
- Must cover at least half of group operations

**Score 4**: Charter explicitly covers acute and chronic hazards; review ≥2x/year; ≥80% subsidiaries; near/medium/long time horizons referenced.
- Example: "Risk Committee charter assigns oversight of acute hazards (floods, storms, wildfires) and chronic hazards (sea level rise, heat stress), reviewed semi-annually across 85% of operations, covering near-term (2030), medium-term (2050), and long-term (2100) scenarios"
- Must have documented charter or mandate
- Must specify both acute and chronic hazards
- Must review at least twice per year
- Must cover at least 80% of operations

**Score 5**: Group-wide (≥95%) oversight with quarterly reporting including peril-region dashboards; integration with strategy; external assurance over governance disclosures.
- Example: "Board receives quarterly dashboards showing physical risk exposures by peril (floods, storms, heat, wildfires, sea level rise) and region for 100% of operating entities, with external assurance over governance disclosures and integration into strategic planning and capital allocation"
- Must cover ≥95% of group
- Must have quarterly (or more frequent) reporting
- Must include granular peril-region data
- Must integrate with strategy and capital allocation
- Ideally has external assurance

**Mandatory Evidence for Score > 0**:
- Verbatim quote mentioning board/committee AND physical climate risks
- Source document (e.g., Annual Report, TCFD Report, Governance Charter)
- Page number or section reference

---

### M02 - Senior management responsibility

**Standard Name**: `Senior management responsibility`

**Expanded Definition**:
Named executive (C-suite or senior management) with **explicit accountability** for managing the company's exposure to **physical climate risks**, including clear reporting line to CEO/Board, defined remit across enterprise functions, and resources (team, budget) to execute responsibilities. This measure assesses whether there is a specific person responsible for physical risk management (not just "climate" generally).

**What MUST be present for high scores**:
- ✅ **Named executive** (name and title, e.g., "John Smith, Chief Risk Officer")
- ✅ **Explicit responsibility for physical climate risks** (not just "climate" or "sustainability")
- ✅ **Reporting line** (e.g., "reports to CEO", "reports to Board Risk Committee")
- ✅ **Remit** (which functions, geographies, or business units covered)
- ✅ **Resources** (team size, budget, KPIs) for score 4-5

**What does NOT qualify**:
- ❌ Generic "Chief Sustainability Officer" without physical risk specificity
- ❌ "Climate strategy" or "net zero" responsibility without physical risk mention
- ❌ Unnamed role (e.g., "management oversees climate risks")
- ❌ Implied responsibility without explicit documentation

**Scoring Criteria**:

**Score 0**: No named executive responsible for physical climate risk management.

**Score 1**: Generic mention of management oversight of "climate" without physical risk specificity or named individual.
- Example: "Management team oversees climate strategy"

**Score 2**: Role implied or generic title (e.g., "Chief Risk Officer") without explicit physical risk responsibility; OR named but no reporting line; OR <50% scope.
- Example: "Chief Risk Officer manages enterprise risks including climate" (not explicit about physical)

**Score 3**: Named executive with explicit physical risk responsibility, reporting line, and remit; reports at least annually to Board/CEO; ≥50% scope.
- Example: "Jane Doe, Chief Operating Officer, is responsible for managing physical climate risks across operations, reports annually to the Board Risk Committee, covering 60% of facilities"

**Score 4**: Executive with dedicated team (FTE count), budget, and KPIs; reports ≥2x/year; ≥80% scope.
- Example: "John Smith, EVP Risk Management, leads a team of 5 FTEs with a $2M annual budget to manage physical climate risks, reports semi-annually to the Board, covering 85% of operations, with KPIs on downtime reduction and adaptation spend"

**Score 5**: Enterprise-wide remit (≥95%) with cross-functional governance, quantified KPIs tied to outcomes, and integration into planning and compensation.
- Example: "Chief Resilience Officer oversees physical climate risk management across 100% of operations with cross-functional governance (operations, finance, strategy), KPIs tied to business interruption reduction and adaptation ROI, integrated into annual planning and executive compensation"

---

### M03 - ERM integration of physical risk

**Standard Name**: `ERM integration of physical risk`

**Expanded Definition**:
Degree to which **physical climate risks** are embedded in the company's Enterprise Risk Management (ERM) framework, including:
- Inclusion in risk taxonomy or risk register
- Risk appetite statements and tolerance levels
- Risk assessment methodology and frequency
- Integration into strategic planning and capital allocation
- Linkage to business unit risk management

This measure assesses whether physical climate risks are treated as a formal enterprise risk (not just a sustainability issue).

**What MUST be present for high scores**:
- ✅ **Physical climate risks listed in risk taxonomy** or risk register
- ✅ **Risk appetite statement** or tolerance levels for physical risks
- ✅ **Regular risk assessment** (annual minimum)
- ✅ **Integration into strategic planning** and capital allocation
- ✅ **Linkage to business unit risk management**

**What does NOT qualify**:
- ❌ Generic "climate risk" in risk register without physical specificity
- ❌ Only transition risk or emissions risk (not physical)
- ❌ "Sustainability risks" without physical climate risk specificity
- ❌ Ad hoc consideration without formal ERM integration

**Scoring Criteria**:

**Score 0**: Physical climate risks not mentioned in ERM framework or risk register.

**Score 1**: Generic mention of "climate risk" in ERM without physical risk specificity.
- Example: "Climate change is identified as an emerging risk"

**Score 2**: Listed in risk register but no risk appetite/tolerance defined; OR ad hoc updates; OR <50% functions covered.
- Example: "Physical climate risks are included in the risk register" (but no appetite or tolerance)

**Score 3**: In risk taxonomy with defined tolerances and annual risk assessment; ≥50% functions covered; hazards or financial impacts referenced.
- Example: "Physical climate risks (floods, storms, heat) are in our risk taxonomy with defined tolerance levels (e.g., <5% revenue impact), assessed annually across 60% of business units"

**Score 4**: Linked to strategy and capital allocation; ≥80% functions; multi-hazard and multi-horizon analysis; quantified risk appetite.
- Example: "Physical climate risks are integrated into strategic planning with risk-adjusted capital allocation, assessed across 85% of business units, covering acute and chronic hazards across near/medium/long horizons, with quantified risk appetite (e.g., <$50M annual loss tolerance)"

**Score 5**: Enterprise-wide integration (≥95%) with risk-adjusted capital metrics, scenario-linked appetites, and routine board review.
- Example: "Physical climate risks are fully integrated into ERM across 100% of operations with risk-adjusted return on capital (RAROC) metrics, scenario-based risk appetites linked to RCP pathways, and quarterly board review"

---

### M04 - Public adaptation/resilience commitments

**Standard Name**: `Public adaptation/resilience commitments`

**Expanded Definition**:
Time-bound public targets, goals, or commitments specifically for **reducing physical climate risk exposure** and **improving resilience**, including:
- Capital expenditure (capex) commitments for adaptation
- Operating expenditure (opex) for resilience programs
- Targets for retrofitting, hardening, or relocating assets
- Targets for reducing downtime or business interruption
- Targets for improving climate resilience metrics

This measure assesses whether the company has made **public, quantified, time-bound commitments** to invest in physical climate adaptation (not just general sustainability commitments).

**What MUST be present for high scores**:
- ✅ **Public commitment** (disclosed in report or website)
- ✅ **Time-bound target** (e.g., "by 2030", "by 2025")
- ✅ **Quantified investment** (e.g., "$100M capex", "5% of total capex")
- ✅ **Specific to physical risk adaptation** (not emissions reduction)
- ✅ **Scope** (which assets, geographies, or hazards covered)

**What does NOT qualify**:
- ❌ Generic "climate investment" without adaptation specificity
- ❌ Emissions reduction or renewable energy investment (transition, not adaptation)
- ❌ "Sustainability investment" without physical risk specificity
- ❌ Intent to invest without quantified amounts or timelines

**Scoring Criteria**:

**Score 0**: No public commitments for physical climate adaptation or resilience.

**Score 1**: Intent to invest in resilience without quantified amounts or timelines.
- Example: "We are committed to improving climate resilience"

**Score 2**: Target or budget stated but <50% scope OR single hazard only.
- Example: "$10M investment in flood protection for 3 facilities" (<50% of facilities)

**Score 3**: Time-bound targets with quantified budget; ≥50% sites; multi-hazard.
- Example: "$50M investment by 2030 to retrofit 60% of facilities against floods, storms, and heat"

**Score 4**: Multi-hazard program with annual spend tracking and KPI monitoring; ≥80% sites; near/medium/long horizons.
- Example: "$200M over 5 years (2025-2030) to improve resilience of 85% of facilities against floods, storms, heat, and wildfires, with annual KPI tracking on downtime reduction and adaptation ROI"

**Score 5**: Group-wide (≥95%) with hazard-region budgeting, ROI tracking, and third-party validation.
- Example: "$500M commitment (2025-2035) for 100% of facilities with hazard-specific budgets by region (e.g., $50M for coastal flood protection, $100M for wildfire hardening), ROI tracking, and third-party validation of adaptation effectiveness"

---

### M05 - Scenario analysis & strategic planning

**Standard Name**: `Scenario analysis & strategic planning`

**Expanded Definition**:
Use of **physical climate scenarios** (e.g., RCP 2.6, RCP 4.5, RCP 8.5, SSP1-2.6, SSP5-8.5) to assess future physical climate risk exposure and inform strategic planning, capital allocation, and long-term resilience planning. This includes:
- Scenario selection (which RCP/SSP pathways)
- Time horizons analyzed (e.g., 2030, 2050, 2100)
- Hazards analyzed (which physical risks)
- Financial impact quantification
- Integration into strategy and capital allocation

This measure assesses whether the company uses **forward-looking climate scenarios** to understand future physical risk exposure (not just current risk assessment).

**What MUST be present for high scores**:
- ✅ **Specific scenarios used** (e.g., "RCP 4.5 and RCP 8.5", "SSP1-2.6 and SSP5-8.5")
- ✅ **Time horizons** (e.g., "2030, 2050, 2100")
- ✅ **Hazards analyzed** (e.g., "floods, storms, heat, sea level rise")
- ✅ **Financial impacts** quantified (for score 4-5)
- ✅ **Integration into strategy** and capital allocation (for score 4-5)

**What does NOT qualify**:
- ❌ Generic "scenario analysis" without specific RCP/SSP pathways
- ❌ Only transition risk scenarios (e.g., IEA Net Zero Scenario) without physical risk
- ❌ Qualitative scenarios without quantified impacts
- ❌ Single scenario or single time horizon

**Scoring Criteria**:

**Score 0**: No physical climate scenario analysis.

**Score 1**: Mentions scenarios without specifics (no RCP/SSP pathways or hazards).
- Example: "We conduct climate scenario analysis"

**Score 2**: Qualitative scenarios; single hazard or single time horizon; <50% assets.
- Example: "We analyzed flood risk under a high warming scenario for key facilities"

**Score 3**: Multi-scenario analysis (≥2 RCPs/SSPs); ≥2 time horizons; ≥50% assets; qualitative impacts.
- Example: "We analyzed physical climate risks under RCP 4.5 and RCP 8.5 for 2030 and 2050, covering floods, storms, and heat for 60% of facilities, with qualitative impact assessment"

**Score 4**: Quantified financial impacts; ≥3 hazards; ≥80% assets; near/medium/long horizons; linked to strategy.
- Example: "We analyzed physical climate risks under RCP 2.6, 4.5, and 8.5 for 2030, 2050, and 2100, covering floods, storms, heat, wildfires, and sea level rise for 85% of facilities, with quantified financial impacts ($50M-$200M potential losses) and integration into strategic planning and capital allocation"

**Score 5**: Group-wide (≥95%) multi-hazard, multi-scenario analysis with quantified impacts, capital allocation adjustments, and third-party validation.
- Example: "We conducted comprehensive scenario analysis under RCP 2.6, 4.5, and 8.5 for 2030, 2050, and 2100, covering all major hazards for 100% of operations, with quantified financial impacts by hazard and region, capital allocation adjustments based on scenario results, and third-party validation by climate science experts"

---

### M06 - Stakeholder engagement on physical risk

**Standard Name**: `Stakeholder engagement on physical risk`

**Expanded Definition**:
Engagement with investors, regulators, employees, communities, suppliers, customers, and other stakeholders specifically on **physical climate risk management** and adaptation plans. This includes:
- Investor engagement (e.g., investor calls, roadshows, AGM discussions)
- Regulatory engagement (e.g., consultations, filings)
- Employee engagement (e.g., training, communications)
- Community engagement (e.g., consultations, partnerships)
- Supplier engagement (e.g., questionnaires, audits)
- Customer engagement (e.g., product resilience, service continuity)

This measure assesses whether the company actively engages stakeholders on physical climate risks (not just general ESG or sustainability).

**What MUST be present for high scores**:
- ✅ **Multiple stakeholder groups** engaged (≥2 for score 3, ≥3 for score 4)
- ✅ **Regular engagement** (annual minimum)
- ✅ **Specific to physical climate risks** (not just "climate" or "sustainability")
- ✅ **Feedback integration** into strategy or operations (for score 4-5)
- ✅ **Public disclosure** of engagement activities

**What does NOT qualify**:
- ❌ Generic "stakeholder engagement" without physical risk specificity
- ❌ Only emissions or net zero engagement (transition, not physical)
- ❌ "Sustainability" engagement without physical risk mention
- ❌ Ad hoc engagement without regular cadence

**Scoring Criteria**:

**Score 0**: No stakeholder engagement on physical climate risks.

**Score 1**: Generic mention of stakeholder engagement on "climate" without physical risk specificity.
- Example: "We engage stakeholders on climate matters"

**Score 2**: Ad hoc engagement; single stakeholder group; <50% scope.
- Example: "We engaged investors on climate risks in 2023" (ad hoc, not regular)

**Score 3**: Regular engagement (≥annual) with ≥2 stakeholder groups specifically on physical climate risks; ≥50% scope.
- Example: "We engage investors and employees annually on physical climate risks including floods, storms, and heat, covering 60% of operations"

**Score 4**: Multi-stakeholder engagement (≥3 groups); ≥2x/year; ≥80% scope; feedback integration documented.
- Example: "We engage investors, employees, and communities semi-annually on physical climate risks, covering 85% of operations, with documented feedback integration into adaptation planning"

**Score 5**: Comprehensive engagement across all major stakeholder groups with documented feedback loops, public disclosure, and integration into decision-making.
- Example: "We engage investors, regulators, employees, communities, suppliers, and customers on physical climate risks with documented feedback loops, quarterly public disclosure, and integration into strategic planning and capital allocation"

---

### M07 - Policy advocacy & industry collaboration

**Standard Name**: `Policy advocacy & industry collaboration`

**Expanded Definition**:
Participation in industry initiatives, policy advocacy, and collaborative efforts specifically to advance **physical climate risk management** and adaptation. This includes:
- Membership in industry associations or coalitions focused on climate adaptation
- Participation in policy consultations on physical climate risk
- Collaboration with peers on adaptation best practices
- Support for adaptation-related regulations or standards
- Leadership roles in industry initiatives

This measure assesses whether the company is actively contributing to broader efforts to improve physical climate risk management (not just internal efforts).

**What MUST be present for high scores**:
- ✅ **Named industry initiatives** or associations
- ✅ **Specific to physical climate adaptation** (not just "climate" generally)
- ✅ **Active participation** or leadership roles
- ✅ **Policy advocacy** on adaptation-related issues
- ✅ **Documented impact** on standards or regulations (for score 5)

**What does NOT qualify**:
- ❌ Generic "industry collaboration" without adaptation specificity
- ❌ Only emissions or net zero advocacy (transition, not adaptation)
- ❌ "Sustainability" initiatives without physical risk focus
- ❌ Passive membership without active participation

**Scoring Criteria**:

**Score 0**: No policy advocacy or industry collaboration on physical climate adaptation.

**Score 1**: Generic mention of industry participation without adaptation specificity.
- Example: "We participate in climate-related industry initiatives"

**Score 2**: Participation in ≥1 initiative but no leadership or active advocacy.
- Example: "We are members of the Climate Resilience Coalition"

**Score 3**: Active participation in ≥2 initiatives with some policy advocacy on adaptation.
- Example: "We actively participate in the Climate Adaptation Alliance and the Infrastructure Resilience Forum, and submitted comments on proposed flood risk disclosure regulations"

**Score 4**: Leadership roles in ≥2 initiatives; active policy advocacy; ≥3 collaborative projects.
- Example: "We chair the Climate Adaptation Alliance's working group on asset hardening, actively advocate for improved building codes for extreme weather, and lead 3 collaborative projects on nature-based solutions"

**Score 5**: Industry leadership with multiple initiatives, policy advocacy at national/international level, and documented impact on standards/regulations.
- Example: "We lead the Global Climate Adaptation Council, actively advocate for physical climate risk disclosure regulations at national and international levels, and our advocacy contributed to the adoption of new building codes for flood and wildfire resilience in 5 jurisdictions"

---

## CATEGORY 2: RISK IDENTIFICATION & ASSESSMENT

### M08 - Hazard identification & prioritization

**Standard Name**: `Hazard identification & prioritization`

**Expanded Definition**:
Systematic identification and prioritization of **acute and chronic physical climate hazards** relevant to the company's operations, assets, and value chain. This includes:
- Identification of specific hazards (floods, storms, hurricanes, cyclones, typhoons, wildfires, heat waves, droughts, sea level rise, coastal erosion, precipitation changes, etc.)
- Geographic specificity (which hazards affect which locations)
- Prioritization methodology (which hazards pose the greatest risk)
- Update frequency (how often hazard assessment is refreshed)
- Coverage across operations (which assets, facilities, or business units assessed)

This measure assesses whether the company has a **comprehensive, systematic process** for identifying which physical climate hazards it faces (not just generic "climate risk").

**What MUST be present for high scores**:
- ✅ **Specific hazards identified** (≥3 for score 3, ≥5 for score 4, ≥7 for score 5)
- ✅ **Prioritization method** documented (e.g., risk matrix, scoring system)
- ✅ **Geographic specificity** (which hazards affect which locations)
- ✅ **Regular updates** (annual minimum)
- ✅ **Broad coverage** (≥50% for score 3, ≥80% for score 4, ≥95% for score 5)

**What does NOT qualify**:
- ❌ Generic "climate hazards" without specific identification
- ❌ Only one or two hazards mentioned
- ❌ No prioritization methodology
- ❌ Ad hoc identification without regular updates

**Scoring Criteria**:

**Score 0**: No systematic hazard identification.

**Score 1**: Generic mention of "climate hazards" without specific identification.
- Example: "We face climate-related hazards"

**Score 2**: Identifies ≥3 hazards but no prioritization methodology; <50% assets.
- Example: "We have identified floods, storms, and heat as relevant hazards"

**Score 3**: Systematic identification of ≥5 hazards with prioritization methodology; ≥50% assets; annual updates.
- Example: "We systematically identify and prioritize physical climate hazards (floods, storms, heat, wildfires, droughts) using a risk matrix, assessed annually across 60% of facilities"

**Score 4**: Comprehensive identification of ≥7 hazards with quantified prioritization; ≥80% assets; ≥2x/year updates.
- Example: "We identify and prioritize 8 physical climate hazards (floods, storms, hurricanes, heat, wildfires, droughts, sea level rise, precipitation changes) using a quantified risk scoring system, assessed semi-annually across 85% of operations"

**Score 5**: Group-wide (≥95%) multi-hazard assessment with quantified prioritization, geographic specificity, and integration into risk management.
- Example: "We conduct comprehensive hazard identification for 10+ physical climate hazards across 100% of operations with quantified risk scores by hazard and location, updated quarterly, and integrated into enterprise risk management"

---

### M09 - Asset exposure mapping

**Standard Name**: `Asset exposure mapping`

**Expanded Definition**:
Geospatial mapping of **asset exposure** to identified physical climate hazards, including:
- Mapping of facilities, infrastructure, and critical assets
- Overlay with hazard maps (flood zones, wildfire risk areas, coastal zones, etc.)
- Use of geospatial tools or GIS systems
- Granularity of mapping (facility-level, site-level, asset-level)
- Update frequency

This measure assesses whether the company has **mapped where its assets are located** relative to physical climate hazards (not just identified hazards generally).

**What MUST be present for high scores**:
- ✅ **Geospatial mapping** (not just lists of exposed assets)
- ✅ **Multiple hazards mapped** (≥3 for score 3, ≥5 for score 4)
- ✅ **Broad coverage** (≥50% for score 3, ≥80% for score 4, ≥95% for score 5)
- ✅ **Geospatial tools** used (e.g., GIS, climate risk platforms)
- ✅ **Regular updates** (annual minimum)

**What does NOT qualify**:
- ❌ Lists of exposed assets without geospatial mapping
- ❌ Only one or two hazards mapped
- ❌ No use of geospatial tools
- ❌ Ad hoc mapping without regular updates

**Scoring Criteria**:

**Score 0**: No asset exposure mapping.

**Score 1**: Generic mention of asset exposure without geospatial mapping.
- Example: "Some of our facilities are exposed to floods"

**Score 2**: Mapping for ≥1 hazard; <50% assets.
- Example: "We have mapped flood exposure for key facilities"

**Score 3**: Multi-hazard mapping (≥3 hazards); ≥50% assets; annual updates.
- Example: "We use GIS to map asset exposure to floods, storms, and heat for 60% of facilities, updated annually"

**Score 4**: Comprehensive mapping (≥5 hazards); ≥80% assets; geospatial tools; ≥2x/year updates.
- Example: "We use advanced geospatial tools to map asset exposure to floods, storms, heat, wildfires, and sea level rise for 85% of operations, updated semi-annually"

**Score 5**: Group-wide (≥95%) multi-hazard geospatial mapping with granular location data, third-party tools, and integration into risk management.
- Example: "We use third-party climate risk platforms to map asset exposure to 10+ hazards for 100% of facilities with granular asset-level data, updated quarterly, and integrated into capital planning"

---

### M10 - Vulnerability assessment

**Standard Name**: `Vulnerability assessment`

**Expanded Definition**:
Assessment of **asset and operational vulnerability** to identified hazards, considering:
- Design standards and building codes
- Age and condition of assets
- Criticality to operations
- Existing protection measures
- Vulnerability scoring or classification

This measure assesses whether the company understands **how vulnerable** its assets are to physical climate hazards (not just where they are exposed).

**What MUST be present for high scores**:
- ✅ **Vulnerability assessment** (not just exposure mapping)
- ✅ **Multiple criteria** considered (≥3 for score 3, ≥5 for score 4)
- ✅ **Criticality classification** (which assets are most critical)
- ✅ **Broad coverage** (≥50% for score 3, ≥80% for score 4, ≥95% for score 5)
- ✅ **Regular updates** (annual minimum)

**What does NOT qualify**:
- ❌ Only exposure mapping without vulnerability assessment
- ❌ Generic "some assets are vulnerable" without assessment
- ❌ No criticality classification
- ❌ Ad hoc assessment without regular updates

**Scoring Criteria**:

**Score 0**: No vulnerability assessment.

**Score 1**: Generic mention of vulnerability without systematic assessment.
- Example: "Some assets are vulnerable to extreme weather"

**Score 2**: Assessment for ≥1 hazard; <50% assets; qualitative only.
- Example: "We assessed flood vulnerability for key facilities"

**Score 3**: Multi-hazard assessment (≥3 hazards); ≥50% assets; ≥3 criteria; annual updates.
- Example: "We assess vulnerability to floods, storms, and heat considering design standards, asset age, and criticality for 60% of facilities, updated annually"

**Score 4**: Comprehensive assessment (≥5 hazards); ≥80% assets; quantified vulnerability; criticality classification; ≥2x/year updates.
- Example: "We assess vulnerability to floods, storms, heat, wildfires, and sea level rise using quantified vulnerability scores considering design standards, age, condition, criticality, and existing protections for 85% of operations, with criticality classification, updated semi-annually"

**Score 5**: Group-wide (≥95%) multi-hazard vulnerability assessment with quantified metrics, criticality classification, and integration into capital planning.
- Example: "We conduct comprehensive vulnerability assessment for 10+ hazards across 100% of operations with quantified vulnerability indices, criticality classification (Tier 1/2/3), and integration into capital planning and retrofit prioritization"

---

### M11 - Scenario modeling & quantification

**Standard Name**: `Scenario modeling & quantification`

**Expanded Definition**:
Use of **climate models and scenario analysis** to quantify physical risk exposure and potential impacts under different climate futures. This includes:
- Climate models used (e.g., CMIP6 models, regional climate models)
- Scenarios analyzed (e.g., RCP/SSP pathways)
- Time horizons (e.g., 2030, 2050, 2100)
- Hazards modeled (which physical risks)
- Quantification of impacts (financial, operational, physical)

This measure assesses whether the company uses **quantitative modeling** to understand future physical risk exposure (not just qualitative scenarios).

**What MUST be present for high scores**:
- ✅ **Climate models used** (named models or platforms)
- ✅ **Multiple scenarios** (≥2 for score 3, ≥3 for score 4)
- ✅ **Multiple time horizons** (≥2 for score 3, ≥3 for score 4)
- ✅ **Quantified impacts** (financial or operational metrics)
- ✅ **Broad coverage** (≥50% for score 3, ≥80% for score 4, ≥95% for score 5)

**What does NOT qualify**:
- ❌ Qualitative scenarios without quantitative modeling
- ❌ Single scenario or single time horizon
- ❌ No quantification of impacts
- ❌ Generic "scenario analysis" without specific models or scenarios

**Scoring Criteria**:

**Score 0**: No scenario modeling or quantification.

**Score 1**: Generic mention of scenarios without quantitative modeling.
- Example: "We consider climate scenarios"

**Score 2**: Qualitative scenarios; single hazard; <50% assets.
- Example: "We qualitatively assessed flood risk under a high warming scenario"

**Score 3**: Multi-scenario modeling (≥2 scenarios); ≥3 hazards; ≥50% assets; qualitative impacts.
- Example: "We modeled physical climate risks under RCP 4.5 and RCP 8.5 for 2030 and 2050, covering floods, storms, and heat for 60% of facilities, with qualitative impact assessment"

**Score 4**: Quantified modeling (≥3 scenarios); ≥5 hazards; ≥80% assets; financial impacts; near/medium/long horizons.
- Example: "We used CMIP6 climate models to quantify physical climate risks under RCP 2.6, 4.5, and 8.5 for 2030, 2050, and 2100, covering floods, storms, heat, wildfires, and sea level rise for 85% of facilities, with quantified financial impacts ($50M-$200M potential losses)"

**Score 5**: Group-wide (≥95%) multi-hazard, multi-scenario modeling with quantified financial impacts, probabilistic analysis, and third-party validation.
- Example: "We conducted comprehensive probabilistic modeling using CMIP6 models under RCP 2.6, 4.5, and 8.5 for 2030, 2050, and 2100, covering 10+ hazards for 100% of operations, with quantified financial impacts by hazard and region, probabilistic risk distributions, and third-party validation"

---

### M12 - Financial impact quantification

**Standard Name**: `Financial impact quantification`

**Expanded Definition**:
Quantification of **potential financial impacts** from physical climate risks, including:
- Damage costs (asset repair/replacement)
- Business interruption losses (revenue loss, downtime costs)
- Supply chain disruption costs
- Adaptation/mitigation costs
- Insurance costs

This measure assesses whether the company has **quantified the financial implications** of physical climate risks (not just identified risks qualitatively).

**What MUST be present for high scores**:
- ✅ **Quantified financial impacts** (dollar amounts or ranges)
- ✅ **Multiple impact types** (≥2 for score 3, ≥3 for score 4)
- ✅ **Time horizons** (near/medium/long term)
- ✅ **Confidence levels** or probability distributions (for score 4-5)
- ✅ **Broad coverage** (≥50% for score 3, ≥80% for score 4, ≥95% for score 5)

**What does NOT qualify**:
- ❌ Qualitative impacts without quantification
- ❌ Generic "financial risks" without specific dollar amounts
- ❌ Only historical losses without forward-looking quantification
- ❌ Single impact type or single time horizon

**Scoring Criteria**:

**Score 0**: No financial impact quantification.

**Score 1**: Generic mention of financial impacts without quantification.
- Example: "Physical climate risks could impact our financial performance"

**Score 2**: Qualitative impacts; single metric; <50% assets.
- Example: "Floods could cause significant damage costs"

**Score 3**: Quantified impacts (≥2 metrics); ≥50% assets; single horizon.
- Example: "We estimate potential damage costs of $20M-$50M and business interruption losses of $10M-$30M from floods and storms for 60% of facilities under current climate"

**Score 4**: Comprehensive quantification (≥3 metrics); ≥80% assets; near/medium/long horizons; confidence levels.
- Example: "We quantified potential financial impacts for 85% of operations across near-term (2030), medium-term (2050), and long-term (2100), including damage costs ($50M-$150M), business interruption ($30M-$100M), and adaptation costs ($200M), with 80% confidence intervals"

**Score 5**: Group-wide (≥95%) quantification with multiple metrics, probabilistic analysis, and integration into financial planning.
- Example: "We quantified potential financial impacts for 100% of operations with probabilistic distributions for damage costs, business interruption, supply chain disruption, and adaptation costs across multiple scenarios and time horizons, integrated into financial planning and capital allocation"

---

### M13 - Supply chain risk assessment

**Standard Name**: `Supply chain risk assessment`

**Expanded Definition**:
Assessment of **physical climate risks in the supply chain**, including:
- Supplier exposure to physical climate hazards
- Supplier criticality (which suppliers are most important)
- Supplier vulnerability (how vulnerable are suppliers)
- Geographic concentration risks
- Tier 1, Tier 2, and beyond supplier assessment

This measure assesses whether the company understands physical climate risks **beyond its own operations** in the supply chain.

**What MUST be present for high scores**:
- ✅ **Supplier risk assessment** (not just own operations)
- ✅ **Multiple hazards** assessed (≥3 for score 3, ≥5 for score 4)
- ✅ **Criticality classification** (which suppliers are most critical)
- ✅ **Broad coverage** (≥50% by spend for score 3, ≥80% for score 4, ≥95% for score 5)
- ✅ **Regular updates** (annual minimum)

**What does NOT qualify**:
- ❌ Only own operations assessed (not supply chain)
- ❌ Generic "supply chain risks" without physical climate specificity
- ❌ No criticality classification
- ❌ Ad hoc assessment without regular updates

**Scoring Criteria**:

**Score 0**: No supply chain risk assessment for physical climate risks.

**Score 1**: Generic mention of supply chain risks without physical climate specificity.
- Example: "We assess supply chain risks"

**Score 2**: Assessment for ≥1 hazard; <50% suppliers (by spend).
- Example: "We assessed flood risk for key suppliers"

**Score 3**: Multi-hazard assessment (≥3 hazards); ≥50% suppliers; criticality classification; annual updates.
- Example: "We assess supplier exposure to floods, storms, and heat for 60% of suppliers by spend, with criticality classification, updated annually"

**Score 4**: Comprehensive assessment (≥5 hazards); ≥80% suppliers; geospatial mapping; ≥2x/year updates.
- Example: "We use geospatial tools to assess supplier exposure to floods, storms, heat, wildfires, and droughts for 85% of suppliers by spend, with criticality classification and geographic concentration analysis, updated semi-annually"

**Score 5**: Group-wide (≥95%) multi-hazard supply chain assessment with geospatial mapping, criticality classification, and integration into procurement.
- Example: "We conduct comprehensive supply chain risk assessment for 10+ hazards covering 100% of suppliers by spend with geospatial mapping, criticality classification (Tier 1/2/3), multi-tier supplier assessment, and integration into procurement and supplier selection"

---

### M14 - Third-party validation & external review

**Standard Name**: `Third-party validation & external review`

**Expanded Definition**:
Use of **third-party experts, consultants, or auditors** to validate physical risk assessments and adaptation plans. This includes:
- Climate science experts
- Engineering consultants
- Risk modeling firms
- External auditors
- Academic institutions

This measure assesses whether the company seeks **independent validation** of its physical climate risk assessments (not just internal assessments).

**What MUST be present for high scores**:
- ✅ **Third-party validation** used (not just internal assessment)
- ✅ **Named validator** (company or institution name)
- ✅ **Scope of validation** (what was validated)
- ✅ **Regular validation** (annual minimum for score 3, ≥2x/year for score 4)
- ✅ **Public disclosure** of validation results (for score 4-5)

**What does NOT qualify**:
- ❌ Only internal assessment without external validation
- ❌ Generic "external review" without named validator
- ❌ Ad hoc validation without regular cadence
- ❌ No public disclosure of validation results

**Scoring Criteria**:

**Score 0**: No third-party validation.

**Score 1**: Generic mention of external review without specifics.
- Example: "We seek external input on climate risks"

**Score 2**: Ad hoc validation; limited scope (<50%).
- Example: "We engaged a consultant to review flood risk for key facilities in 2023"

**Score 3**: Regular validation (≥annual); ≥50% scope; named validator.
- Example: "We engage XYZ Climate Risk Consulting annually to validate our physical climate risk assessments for 60% of operations"

**Score 4**: Comprehensive validation (≥2x/year); ≥80% scope; multiple validators; public disclosure.
- Example: "We engage ABC Engineering and DEF Climate Science semi-annually to validate our physical climate risk assessments and adaptation plans for 85% of operations, with public disclosure of validation results in our TCFD report"

**Score 5**: Group-wide (≥95%) validation with multiple third-party experts, public disclosure of findings, and integration into governance.
- Example: "We engage multiple third-party experts (climate scientists, engineers, risk modelers) to validate our physical climate risk assessments and adaptation plans for 100% of operations, with public disclosure of validation findings and integration into board oversight"

---

### M15 - Regulatory compliance & disclosure

**Standard Name**: `Regulatory compliance & disclosure`

**Expanded Definition**:
Compliance with **physical climate risk disclosure regulations** and voluntary frameworks, including:
- TCFD (Task Force on Climate-related Financial Disclosures)
- ISSB (International Sustainability Standards Board)
- CSRD (Corporate Sustainability Reporting Directive)
- SEC Climate Rule (if applicable)
- Other jurisdictional requirements

This measure assesses whether the company **discloses physical climate risks** in accordance with regulatory requirements and best practice frameworks.

**What MUST be present for high scores**:
- ✅ **Framework alignment** (≥1 for score 2, ≥2 for score 3, ≥3 for score 4)
- ✅ **Comprehensive disclosure** (all TCFD pillars: Governance, Strategy, Risk Management, Metrics & Targets)
- ✅ **Physical risk specificity** (not just "climate risk" generally)
- ✅ **Regular disclosure** (annual minimum)
- ✅ **External assurance** (for score 5)

**What does NOT qualify**:
- ❌ Generic "climate disclosure" without physical risk specificity
- ❌ Only emissions disclosure (not physical risk)
- ❌ Partial disclosure (e.g., only governance, not strategy)
- ❌ No framework alignment

**Scoring Criteria**:

**Score 0**: No regulatory compliance or disclosure of physical climate risks.

**Score 1**: Minimal disclosure; no framework alignment.
- Example: "We face climate-related risks" (generic statement)

**Score 2**: Disclosure aligned with ≥1 framework; limited detail.
- Example: "We disclose physical climate risks in accordance with TCFD recommendations" (but limited detail)

**Score 3**: Comprehensive disclosure aligned with ≥2 frameworks; annual updates.
- Example: "We provide comprehensive physical climate risk disclosure aligned with TCFD and ISSB, covering governance, strategy, risk management, and metrics, updated annually"

**Score 4**: High-quality disclosure aligned with ≥3 frameworks; ≥2x/year updates; regulatory compliance.
- Example: "We provide high-quality physical climate risk disclosure aligned with TCFD, ISSB, and CSRD, with semi-annual updates, full regulatory compliance, and granular data"

**Score 5**: Exemplary disclosure aligned with all major frameworks, regulatory compliance, external assurance, and leading practice.
- Example: "We provide exemplary physical climate risk disclosure aligned with TCFD, ISSB, CSRD, and SEC Climate Rule, with quarterly updates, full regulatory compliance, external assurance over disclosures, and recognition as leading practice"

---

### M16 - Disclosure quality & transparency

**Standard Name**: `Disclosure quality & transparency`

**Expanded Definition**:
Quality, comprehensiveness, and transparency of **physical climate risk disclosures** in public reports. This includes:
- Level of detail (generic vs. specific)
- Data granularity (aggregate vs. facility-level)
- Comprehensiveness (how many of the 44 measures disclosed)
- Accessibility (easy to find and understand)
- Frequency of updates

This measure assesses the **quality** of physical climate risk disclosures (not just whether they exist).

**What MUST be present for high scores**:
- ✅ **High level of detail** (specific hazards, locations, impacts)
- ✅ **Granular data** (facility-level, asset-level)
- ✅ **Comprehensive coverage** (≥50% of measures for score 3, ≥80% for score 4, ≥95% for score 5)
- ✅ **Multiple disclosure channels** (annual report, sustainability report, TCFD report, website)
- ✅ **Frequent updates** (annual minimum, ≥2x/year for score 4, quarterly for score 5)

**What does NOT qualify**:
- ❌ Generic disclosures without specifics
- ❌ Aggregate data only (no granularity)
- ❌ Limited coverage (few measures disclosed)
- ❌ Infrequent updates (less than annual)

**Scoring Criteria**:

**Score 0**: No disclosure of physical climate risks.

**Score 1**: Minimal disclosure; generic statements.
- Example: "We face physical climate risks"

**Score 2**: Some disclosure but limited detail; <50% measures disclosed.
- Example: "We have identified floods and storms as key risks and are taking steps to improve resilience"

**Score 3**: Comprehensive disclosure; ≥50% measures; annual updates; quantitative data.
- Example: "We provide comprehensive physical climate risk disclosure covering governance, risk identification, asset exposure, vulnerability, scenario analysis, adaptation investments, and KPIs (covering ~25 of 44 measures), updated annually with quantitative data"

**Score 4**: High-quality disclosure; ≥80% measures; ≥2x/year updates; granular data; multiple channels.
- Example: "We provide high-quality physical climate risk disclosure covering ~35 of 44 measures, updated semi-annually with facility-level data, disclosed across annual report, sustainability report, TCFD report, and website"

**Score 5**: Exemplary disclosure; ≥95% measures; real-time or quarterly updates; granular data; multiple channels; external assurance.
- Example: "We provide exemplary physical climate risk disclosure covering ~42 of 44 measures, updated quarterly with asset-level data, disclosed across multiple channels including real-time dashboards, with external assurance and recognition as leading practice"

---

## CATEGORY 3: ASSET DESIGN & RESILIENCE

### M17 - Climate-resilient design standards

**Standard Name**: `Climate-resilient design standards`

**Expanded Definition**:
Adoption of **climate-resilient design standards** for new construction and major renovations, incorporating future climate projections. This includes:
- Design standards for specific hazards (flood-resistant design, wind-resistant design, heat-resistant design, etc.)
- Use of future climate projections (not just historical climate)
- Coverage of new construction and major renovations
- Integration into capital planning and engineering standards

This measure assesses whether the company **builds resilience into new assets** from the start (not just retrofitting existing assets).

**What MUST be present for high scores**:
- ✅ **Climate-resilient design standards** adopted
- ✅ **Multiple hazards** addressed (≥3 for score 3, ≥5 for score 4)
- ✅ **Future climate projections** incorporated
- ✅ **Broad coverage** (≥50% of new assets for score 3, ≥80% for score 4, ≥95% for score 5)
- ✅ **Documented implementation**

**What does NOT qualify**:
- ❌ Generic "sustainable design" without climate resilience specificity
- ❌ Only historical climate considerations (not future projections)
- ❌ Ad hoc resilient design without formal standards
- ❌ Limited coverage (<50% of new assets)

**Scoring Criteria**:

**Score 0**: No climate-resilient design standards.

**Score 1**: Generic mention of resilient design without specifics.
- Example: "We consider climate resilience in new construction"

**Score 2**: Standards for ≥1 hazard; <50% new assets.
- Example: "We use flood-resistant design for new facilities in flood-prone areas"

**Score 3**: Multi-hazard standards (≥3 hazards); ≥50% new assets; climate projections incorporated.
- Example: "We have adopted climate-resilient design standards for floods, storms, and heat, applied to 60% of new construction, incorporating future climate projections (RCP 4.5 for 2050)"

**Score 4**: Comprehensive standards (≥5 hazards); ≥80% new assets; future climate scenarios; documented implementation.
- Example: "We have comprehensive climate-resilient design standards for floods, storms, heat, wildfires, and sea level rise, applied to 85% of new construction and major renovations, incorporating future climate scenarios (RCP 4.5 and 8.5 for 2050 and 2100), with documented implementation in engineering standards"

**Score 5**: Group-wide (≥95%) climate-resilient design standards with future projections, third-party certification, and integration into capital planning.
- Example: "We have group-wide climate-resilient design standards for 10+ hazards, applied to 100% of new construction and major renovations, incorporating future climate projections across multiple scenarios and time horizons, with third-party certification (e.g., LEED, BREEAM) and integration into capital planning"

---

### M18 - Retrofitting & hardening programs

**Standard Name**: `Retrofitting & hardening programs`

**Expanded Definition**:
Programs to **retrofit or harden existing assets** to improve resilience to physical climate hazards. This includes:
- Retrofitting programs (upgrading existing assets)
- Hardening measures (strengthening assets against hazards)
- Budget and investment levels
- Coverage of existing asset base
- Completion targets and timelines

This measure assesses whether the company is **improving resilience of existing assets** (not just new construction).

**What MUST be present for high scores**:
- ✅ **Retrofitting/hardening programs** in place
- ✅ **Multiple hazards** addressed (≥3 for score 3, ≥5 for score 4)
- ✅ **Quantified budget** (dollar amounts)
- ✅ **Broad coverage** (≥50% of assets for score 3, ≥80% for score 4, ≥95% for score 5)
- ✅ **Completion targets** and timelines

**What does NOT qualify**:
- ❌ Generic "asset upgrades" without climate resilience specificity
- ❌ Ad hoc retrofitting without systematic program
- ❌ No quantified budget or investment levels
- ❌ Limited coverage (<50% of assets)

**Scoring Criteria**:

**Score 0**: No retrofitting or hardening programs.

**Score 1**: Generic mention of retrofitting without specifics.
- Example: "We upgrade assets to improve resilience"

**Score 2**: Ad hoc retrofitting; <50% assets; single hazard.
- Example: "We have retrofitted some facilities for flood protection"

**Score 3**: Systematic retrofitting program; ≥50% assets; ≥3 hazards; quantified budget.
- Example: "We have a systematic retrofitting program for floods, storms, and heat, covering 60% of facilities, with a $50M budget over 5 years"

**Score 4**: Comprehensive program; ≥80% assets; ≥5 hazards; multi-year plan; KPI tracking.
- Example: "We have a comprehensive retrofitting program for floods, storms, heat, wildfires, and sea level rise, covering 85% of facilities, with a $200M budget over 10 years, multi-year implementation plan, and KPI tracking on completion rates and risk reduction"

**Score 5**: Group-wide (≥95%) retrofitting program with quantified ROI, multi-hazard focus, and integration into capital planning.
- Example: "We have a group-wide retrofitting program for 10+ hazards, covering 100% of facilities, with a $500M budget over 15 years, quantified ROI analysis, and integration into capital planning and asset management"

---

### M19 - Nature-based solutions

**Standard Name**: `Nature-based solutions`

**Expanded Definition**:
Use of **nature-based solutions** (NBS) to reduce physical climate risk exposure. This includes:
- Green infrastructure (green roofs, permeable pavements, rain gardens, etc.)
- Natural barriers (wetlands, mangroves, dunes, forests, etc.)
- Ecosystem restoration (reforestation, wetland restoration, coral reef restoration, etc.)
- Integration with gray infrastructure

This measure assesses whether the company uses **natural systems** to improve climate resilience (not just engineered solutions).

**What MUST be present for high scores**:
- ✅ **Nature-based solutions** implemented
- ✅ **Multiple NBS types** (≥2 for score 3, ≥3 for score 4)
- ✅ **Quantified investment** (dollar amounts)
- ✅ **Assets protected** (percentage or number of assets)
- ✅ **Multiple hazards** addressed (≥2 for score 3, ≥3 for score 4)

**What does NOT qualify**:
- ❌ Generic "environmental programs" without climate resilience specificity
- ❌ Only emissions reduction or biodiversity programs (not resilience)
- ❌ No quantified investment or assets protected
- ❌ Ad hoc NBS without systematic program

**Scoring Criteria**:

**Score 0**: No nature-based solutions for climate resilience.

**Score 1**: Generic mention of NBS without specifics.
- Example: "We support nature-based solutions"

**Score 2**: ≥1 NBS project; <50% assets; single hazard.
- Example: "We have created wetlands for flood protection at 2 facilities"

**Score 3**: ≥3 NBS projects; ≥50% assets; ≥2 hazards; quantified investment.
- Example: "We have implemented 5 nature-based solution projects (wetlands, green roofs, reforestation) protecting 60% of facilities from floods and heat, with a $10M investment"

**Score 4**: Comprehensive NBS program; ≥5 projects; ≥80% assets; ≥3 hazards; ROI tracking.
- Example: "We have a comprehensive nature-based solutions program with 10+ projects (wetlands, mangroves, green infrastructure, reforestation) protecting 85% of facilities from floods, storms, and heat, with a $50M investment and ROI tracking"

**Score 5**: Group-wide (≥95%) NBS program with quantified benefits, multi-hazard focus, and integration into land use planning.
- Example: "We have a group-wide nature-based solutions program with 20+ projects protecting 100% of facilities from multiple hazards, with a $100M investment, quantified benefits (risk reduction, co-benefits), and integration into land use planning and ecosystem management"

---

### M20 - Critical infrastructure protection

**Standard Name**: `Critical infrastructure protection`

**Expanded Definition**:
Enhanced protection measures for **critical infrastructure and high-value assets** against physical climate hazards. This includes:
- Identification of critical assets (which assets are most critical to operations)
- Enhanced protection measures (redundancy, backup systems, hardening, etc.)
- Investment in critical infrastructure protection
- Coverage of critical asset base

This measure assesses whether the company provides **extra protection** for its most critical assets (not just treating all assets equally).

**What MUST be present for high scores**:
- ✅ **Critical assets identified** (number or percentage)
- ✅ **Enhanced protection measures** implemented
- ✅ **Multiple hazards** addressed (≥3 for score 3, ≥5 for score 4)
- ✅ **Quantified investment** (dollar amounts)
- ✅ **Broad coverage** (≥50% of critical assets for score 3, ≥80% for score 4, ≥95% for score 5)

**What does NOT qualify**:
- ❌ Generic "asset protection" without criticality classification
- ❌ No enhanced protection for critical assets
- ❌ Ad hoc protection without systematic program
- ❌ Limited coverage (<50% of critical assets)

**Scoring Criteria**:

**Score 0**: No critical infrastructure protection program.

**Score 1**: Generic mention of asset protection without criticality classification.
- Example: "We protect our assets from climate risks"

**Score 2**: Protection for ≥1 hazard; <50% critical assets.
- Example: "We have enhanced flood protection for key facilities"

**Score 3**: Multi-hazard protection (≥3 hazards); ≥50% critical assets; quantified investment.
- Example: "We have identified 50 critical facilities and implemented enhanced protection against floods, storms, and heat for 60% of them, with a $30M investment"

**Score 4**: Comprehensive protection (≥5 hazards); ≥80% critical assets; documented measures; ROI tracking.
- Example: "We have identified 100 critical facilities and implemented comprehensive protection (redundancy, backup systems, hardening) against floods, storms, heat, wildfires, and sea level rise for 85% of them, with a $100M investment, documented measures, and ROI tracking"

**Score 5**: Group-wide (≥95%) critical infrastructure protection with multi-hazard focus, redundancy, and integration into operations.
- Example: "We have identified all critical infrastructure (100+ facilities) and implemented comprehensive protection with redundancy and backup systems for 10+ hazards, covering 100% of critical assets, with a $200M investment and integration into operations and emergency response"

---

### M21 - Relocation & strategic divestment

**Standard Name**: `Relocation & strategic divestment`

**Expanded Definition**:
Strategic **relocation of assets or divestment** from high-risk locations based on physical climate risk assessments. This includes:
- Relocation of facilities or operations
- Divestment from high-risk assets or locations
- Risk reduction achieved
- Financial impact of relocation/divestment
- Completion targets and timelines

This measure assesses whether the company is willing to **move away from high-risk locations** when adaptation is not feasible or cost-effective.

**What MUST be present for high scores**:
- ✅ **Relocation or divestment projects** completed or planned
- ✅ **Risk-based decision-making** (based on physical climate risk assessments)
- ✅ **Quantified risk reduction** achieved
- ✅ **Financial impact** quantified (value of divested assets, relocation costs)
- ✅ **Completion targets** and timelines

**What does NOT qualify**:
- ❌ Generic "portfolio optimization" without climate risk basis
- ❌ Relocation/divestment for other reasons (not physical climate risk)
- ❌ No quantified risk reduction or financial impact
- ❌ Ad hoc relocation without strategic program

**Scoring Criteria**:

**Score 0**: No relocation or divestment based on physical climate risk.

**Score 1**: Generic mention of relocation/divestment without climate risk basis.
- Example: "We optimize our portfolio"

**Score 2**: ≥1 project; <50% high-risk assets.
- Example: "We relocated 1 facility from a flood-prone area"

**Score 3**: ≥2 projects; ≥50% high-risk assets; quantified risk reduction.
- Example: "We have relocated 3 facilities and divested 2 assets from high-risk areas, covering 60% of identified high-risk assets, with quantified risk reduction (30% reduction in flood exposure)"

**Score 4**: Comprehensive program; ≥3 projects; ≥80% high-risk assets; multi-year plan; financial impact quantified.
- Example: "We have a comprehensive relocation/divestment program with 5 projects covering 85% of high-risk assets, a 10-year implementation plan, quantified risk reduction (50% reduction in overall physical risk exposure), and financial impact analysis ($100M divestment value, $50M relocation costs)"

**Score 5**: Group-wide (≥95%) strategic relocation/divestment program with quantified risk reduction, financial impact, and integration into strategy.
- Example: "We have a group-wide strategic relocation/divestment program covering 100% of high-risk assets, with quantified risk reduction (70% reduction in overall physical risk exposure), comprehensive financial impact analysis, and integration into strategic planning and capital allocation"

---

## CATEGORY 4: CRISIS MANAGEMENT

### M22 - Business continuity plans (BCPs)

**Standard Name**: `Business continuity plans (BCPs)`

**Expanded Definition**:
Comprehensive **business continuity plans** to maintain operations during and after major disruptions, including those caused by physical climate hazards. BCPs are inherently **hazard-agnostic** - a robust plan for hurricanes will typically work for floods, storms, or other major disruptions. This measure assesses:
- Documented response procedures and recovery strategies
- Roles, responsibilities, and escalation protocols
- Recovery time objectives and critical function prioritization
- Testing and drill protocols
- Update frequency and continuous improvement

**Physical Climate Risk Relevance**: While BCPs need not explicitly mention "physical climate risks," they should be **comprehensive enough** to address the types of disruptions that physical climate events cause (facility damage, power outages, supply chain interruption, employee safety, communication disruption, etc.).

**What MUST be present for high scores**:
- ✅ **Business continuity plans** documented and maintained
- ✅ **Comprehensive scope** covering major disruption types (facility damage, power loss, supply chain, employee safety, IT systems, etc.)
- ✅ **Broad coverage** (≥50% of operations for score 3, ≥80% for score 4, ≥95% for score 5)
- ✅ **Regular testing** (annual minimum for score 3, ≥2x/year for score 4)
- ✅ **Regular updates** (annual minimum)
- ✅ **Documented recovery strategies** with time objectives

**What does NOT qualify**:
- ❌ No documented BCPs
- ❌ BCPs that only cover IT/cyber incidents (too narrow)
- ❌ BCPs with no testing or drills
- ❌ Outdated BCPs (not updated in >2 years)
- ❌ Limited coverage (<50% of operations)

**Scoring Criteria**:

**Score 0**: No business continuity plans.

**Score 1**: Generic mention of BCPs without documentation or limited scope.
- Example: "We have business continuity plans" (no evidence of documentation)
- Example: "We have IT disaster recovery plans" (too narrow - only IT)

**Score 2**: Documented BCPs; <50% operations; limited scope; ad hoc testing.
- Example: "We have business continuity plans for key facilities covering facility damage and power outages"
- Covers some but not all major disruption types
- Testing is ad hoc or infrequent

**Score 3**: Comprehensive BCPs; ≥50% operations; covers major disruption types; annual testing and updates.
- Example: "We have comprehensive business continuity plans covering 60% of operations, addressing facility damage, power outages, supply chain disruption, employee safety, and IT systems, tested annually and updated annually"
- Covers most major disruption types that would apply to physical climate events
- Regular testing (at least annual)
- Regular updates (at least annual)

**Score 4**: Comprehensive BCPs; ≥80% operations; ≥2x/year testing; documented recovery strategies with RTOs; continuous improvement.
- Example: "We have comprehensive business continuity plans covering 85% of operations, addressing all major disruption types, tested semi-annually with documented recovery strategies and recovery time objectives (e.g., Tier 1 critical functions: 24 hours, Tier 2: 72 hours), with continuous improvement based on test results"
- Covers all major disruption types
- Frequent testing (semi-annual or better)
- Documented recovery strategies with quantified objectives
- Evidence of continuous improvement

**Score 5**: Group-wide (≥95%) BCPs with comprehensive scope, quarterly testing, external validation, and integration into operations.
- Example: "We have group-wide business continuity plans covering 100% of operations, addressing all major disruption types with detailed recovery strategies and RTOs, tested quarterly with tabletop exercises and full drills, externally validated, and integrated into operations and risk management"
- Full group coverage
- Frequent, rigorous testing (quarterly or better)
- External validation or certification
- Fully integrated into operations

**Note**: BCPs that explicitly mention physical climate hazards (floods, storms, heat, etc.) demonstrate higher relevance, but this is not mandatory if the plans are comprehensive enough to address the disruption types these hazards cause.

---

### M23 - Emergency response protocols

**Standard Name**: `Emergency response protocols`

**Expanded Definition**:
Documented **emergency response protocols** for responding to major emergencies and disasters, including those caused by physical climate events. Emergency response protocols are inherently **hazard-agnostic** - good protocols for hurricanes will work for floods, storms, or other major emergencies. This measure assesses:
- Documented roles, responsibilities, and escalation procedures
- Communication and notification procedures
- Evacuation and shelter-in-place procedures
- Resource mobilization and mutual aid
- Training, drills, and exercises
- Coordination with external emergency services

**Physical Climate Risk Relevance**: While protocols need not explicitly mention "physical climate risks," they should be **comprehensive enough** to address the types of emergencies that physical climate events cause (severe weather, flooding, power outages, facility damage, employee safety threats, etc.).

**What MUST be present for high scores**:
- ✅ **Emergency response protocols** documented and maintained
- ✅ **Comprehensive scope** covering major emergency types (severe weather, facility damage, employee safety, evacuation, communication, etc.)
- ✅ **Broad coverage** (≥50% of operations for score 3, ≥80% for score 4, ≥95% for score 5)
- ✅ **Regular training and drills** (annual minimum for score 3, ≥2x/year for score 4)
- ✅ **Coordination with external services** (fire, police, emergency management)
- ✅ **Activation history** or evidence of readiness

**What does NOT qualify**:
- ❌ No documented emergency response protocols
- ❌ Protocols that only cover workplace safety incidents (too narrow)
- ❌ No training or drills
- ❌ Outdated protocols (not updated in >2 years)
- ❌ Limited coverage (<50% of operations)

**Scoring Criteria**:

**Score 0**: No emergency response protocols.

**Score 1**: Generic mention of emergency response without documentation or limited scope.
- Example: "We have emergency procedures" (no evidence of documentation)
- Example: "We have fire evacuation plans" (too narrow - only fire)

**Score 2**: Documented protocols; <50% operations; limited scope; ad hoc training.
- Example: "We have emergency response protocols for key facilities covering severe weather and evacuation"
- Covers some but not all major emergency types
- Training is ad hoc or infrequent

**Score 3**: Comprehensive protocols; ≥50% operations; covers major emergency types; annual training.
- Example: "We have comprehensive emergency response protocols covering 60% of operations, addressing severe weather, facility damage, employee safety, evacuation, and communication, with annual training and drills"
- Covers most major emergency types that would apply to physical climate events
- Regular training (at least annual)
- Evidence of drills or exercises

**Score 4**: Comprehensive protocols; ≥80% operations; ≥2x/year training; documented activations; external coordination.
- Example: "We have comprehensive emergency response protocols covering 85% of operations, addressing all major emergency types, with semi-annual training and drills, documented activations (5 times in past 3 years), and coordination with local emergency services"
- Covers all major emergency types
- Frequent training (semi-annual or better)
- Evidence of actual use or activation
- Coordination with external emergency services

**Score 5**: Group-wide (≥95%) protocols with comprehensive scope, quarterly drills, external coordination, and continuous improvement.
- Example: "We have group-wide emergency response protocols covering 100% of operations, addressing all major emergency types with detailed procedures, quarterly drills including tabletop exercises and full-scale drills, coordination with local, state, and federal emergency management, and continuous improvement based on lessons learned from drills and actual events"
- Full group coverage
- Frequent, rigorous training (quarterly or better)
- Strong external coordination
- Continuous improvement process

**Note**: Protocols that explicitly mention physical climate hazards (floods, storms, heat, wildfires, etc.) demonstrate higher relevance, but this is not mandatory if the protocols are comprehensive enough to address the emergency types these hazards cause.

---

### M24 - Crisis communication systems

**Standard Name**: `Crisis communication systems`

**Expanded Definition**:
Systems and protocols for **communicating with stakeholders during major crises and emergencies**, including those caused by physical climate events. Crisis communication systems are inherently **hazard-agnostic** - a robust system for hurricanes will work for floods, storms, or other major crises. This measure assesses:
- Communication channels and platforms (email, SMS, phone, mobile app, social media, etc.)
- Stakeholder groups covered (employees, customers, suppliers, communities, investors, regulators, media, etc.)
- Message templates and protocols
- Testing and exercise protocols
- Activation history and performance tracking

**Physical Climate Risk Relevance**: While systems need not explicitly mention "physical climate risks," they should be **comprehensive enough** to handle the communication needs during physical climate events (facility closures, employee safety, service disruptions, supply chain impacts, recovery timelines, etc.).

**What MUST be present for high scores**:
- ✅ **Crisis communication systems** documented and operational
- ✅ **Multiple communication channels** (≥2 for score 3, ≥3 for score 4)
- ✅ **Multiple stakeholder groups** covered (≥2 for score 3, ≥3 for score 4, ≥4 for score 5)
- ✅ **Regular testing** (annual minimum for score 3, ≥2x/year for score 4)
- ✅ **Message templates** or protocols documented
- ✅ **Activation history** or evidence of readiness

**What does NOT qualify**:
- ❌ No documented crisis communication systems
- ❌ Only routine business communication (not crisis-specific)
- ❌ No testing or exercises
- ❌ Single channel only (e.g., only email)
- ❌ Limited stakeholder coverage (<50% of key stakeholders)

**Scoring Criteria**:

**Score 0**: No crisis communication systems.

**Score 1**: Generic mention of communication without crisis specificity or documentation.
- Example: "We communicate with stakeholders" (no crisis-specific system)
- Example: "We have email" (routine communication, not crisis system)

**Score 2**: ≥1 crisis-specific channel; covers <50% stakeholders; ad hoc testing.
- Example: "We use email to notify employees during emergencies"
- Crisis-specific but limited channels and stakeholder coverage
- Testing is ad hoc or infrequent

**Score 3**: ≥2 channels; covers ≥50% stakeholders (e.g., employees + customers); annual testing.
- Example: "We have a crisis communication system using email and SMS to communicate with employees and customers during major emergencies, with documented message templates, tested annually"
- Multiple channels
- Covers major stakeholder groups
- Regular testing (at least annual)

**Score 4**: ≥3 channels; covers ≥80% stakeholders (e.g., employees + customers + suppliers); ≥2x/year testing; documented activations.
- Example: "We have a comprehensive crisis communication system using email, SMS, and mobile app to communicate with employees, customers, and suppliers during major emergencies, with documented protocols and message templates, tested semi-annually, with documented activations (5 times in past 3 years) and performance tracking"
- Multiple diverse channels
- Broad stakeholder coverage
- Frequent testing (semi-annual or better)
- Evidence of actual use

**Score 5**: Group-wide (≥95%) multi-channel system covering all major stakeholders, with real-time capabilities, external coordination, and continuous improvement.
- Example: "We have a group-wide crisis communication system with multiple channels (email, SMS, phone, mobile app, social media, website) covering all major stakeholder groups (employees, customers, suppliers, communities, investors, regulators, media), real-time updates during events, coordination with external emergency management and media, tested quarterly, with documented activations and continuous improvement"
- Comprehensive multi-channel system
- All major stakeholder groups covered
- Real-time capabilities
- External coordination
- Continuous improvement

**Note**: Systems that explicitly address physical climate events demonstrate higher relevance, but this is not mandatory if the systems are comprehensive enough to handle the communication needs these events create.

---

### M25 - Recovery time objectives (RTOs)

**Standard Name**: `Recovery time objectives (RTOs)`

**Expanded Definition**:
Defined **recovery time objectives** for critical operations, systems, and assets following major disruptions, including those caused by physical climate events. RTOs are inherently **hazard-agnostic** - a well-defined RTO for critical manufacturing operations applies regardless of whether the disruption is caused by a hurricane, flood, earthquake, cyberattack, or other event. This measure assesses:
- Quantified time objectives for restoring critical functions
- Criticality classification (Tier 1/2/3 or similar)
- Coverage of critical operations and systems
- Achievement tracking and performance monitoring
- Regular review and continuous improvement

**Physical Climate Risk Relevance**: While RTOs need not explicitly mention "physical climate risks," they should cover the **critical operations and systems** that would be affected by physical climate events (production facilities, distribution centers, IT systems, supply chain, customer service, etc.).

**What MUST be present for high scores**:
- ✅ **RTOs defined** with specific time targets (e.g., "24 hours", "72 hours")
- ✅ **Criticality classification** (which operations are most critical)
- ✅ **Critical operations covered** (≥50% for score 3, ≥80% for score 4, ≥95% for score 5)
- ✅ **Achievement tracking** (actual recovery time vs. RTO target)
- ✅ **Regular review** (annual minimum for score 3, ≥2x/year for score 4)

**What does NOT qualify**:
- ❌ No defined RTOs
- ❌ Generic "recovery plans" without specific time objectives
- ❌ RTOs only for IT systems (too narrow - must include operations)
- ❌ No achievement tracking
- ❌ Limited coverage (<50% of critical operations)

**Scoring Criteria**:

**Score 0**: No RTOs defined.

**Score 1**: Generic mention of recovery objectives without specific time targets or documentation.
- Example: "We aim to recover quickly from disruptions"
- Example: "We have recovery plans" (no specific time objectives)

**Score 2**: RTOs defined for <50% critical operations; no tracking; limited documentation.
- Example: "We have defined RTOs for key facilities (e.g., 24-48 hours)"
- Some RTOs defined but limited coverage
- No systematic tracking

**Score 3**: RTOs for ≥50% critical operations; criticality classification; annual review; some tracking.
- Example: "We have defined RTOs for 60% of critical operations with criticality classification (Tier 1 critical: 24 hours, Tier 2 important: 72 hours, Tier 3 standard: 1 week), reviewed annually, with achievement tracking for Tier 1 operations"
- RTOs cover majority of critical operations
- Criticality classification in place
- Regular review (at least annual)
- Some achievement tracking

**Score 4**: RTOs for ≥80% critical operations; ≥2x/year review; comprehensive achievement tracking; continuous improvement.
- Example: "We have defined RTOs for 85% of critical operations with granular criticality classification, reviewed semi-annually, with comprehensive achievement tracking (90% achievement rate over past 2 years) and continuous improvement process to address gaps"
- RTOs cover most critical operations
- Frequent review (semi-annual or better)
- Comprehensive achievement tracking
- Evidence of continuous improvement

**Score 5**: Group-wide (≥95%) RTOs with granular metrics, real-time tracking, and integration into operations and performance management.
- Example: "We have defined RTOs for 100% of critical operations with granular metrics by operation type and location, real-time achievement tracking integrated into operations dashboards, performance management with accountability for meeting RTOs, and continuous improvement based on actual recovery performance"
- Full coverage of critical operations
- Real-time or near-real-time tracking
- Integration into performance management
- Strong continuous improvement

**Note**: RTOs that explicitly reference physical climate events demonstrate higher relevance, but this is not mandatory if the RTOs cover the critical operations and systems that would be affected by such events.

---

### M26 - Post-event review & continuous improvement

**Standard Name**: `Post-event review & continuous improvement`

**Expanded Definition**:
Systematic **post-event reviews and continuous improvement processes** following major disruptions and emergencies, including those caused by physical climate events. Post-event review processes are inherently **hazard-agnostic** - a robust review process for hurricanes will work for floods, storms, or other major disruptions. This measure assesses:
- Documented post-event review process and protocols
- Events reviewed (percentage of significant events)
- Lessons learned documented and shared
- Improvements identified and implemented
- Implementation tracking and accountability
- Knowledge management and organizational learning

**Physical Climate Risk Relevance**: While review processes need not explicitly focus on "physical climate risks," they should systematically review **major disruptions** including those caused by physical climate events, and the lessons learned should improve resilience to future disruptions of any cause.

**What MUST be present for high scores**:
- ✅ **Post-event review process** documented and followed
- ✅ **Significant events reviewed** (≥50% for score 3, ≥80% for score 4, ≥95% for score 5)
- ✅ **Lessons learned** documented and shared
- ✅ **Improvements identified and implemented** (with examples)
- ✅ **Implementation tracking** and accountability
- ✅ **Regular review** of improvement process

**What does NOT qualify**:
- ❌ No documented review process
- ❌ Generic "continuous improvement" without post-event reviews
- ❌ Reviews conducted but no lessons learned documented
- ❌ Lessons learned documented but no improvements implemented
- ❌ Ad hoc reviews without systematic process

**Scoring Criteria**:

**Score 0**: No post-event review process.

**Score 1**: Generic mention of learning without systematic reviews or documentation.
- Example: "We learn from disruptions"
- Example: "We review incidents" (no evidence of systematic process)

**Score 2**: Ad hoc reviews; <50% significant events; limited documentation.
- Example: "We reviewed the 2023 hurricane impact and made some improvements"
- Reviews are ad hoc, not systematic
- Limited documentation of lessons learned
- Few improvements implemented

**Score 3**: Systematic reviews for ≥50% significant events; documented lessons learned; some improvements implemented.
- Example: "We have a systematic post-event review process, reviewed 60% of significant disruptions in past 3 years (including 2 hurricanes, 1 flood, 1 power outage), documented lessons learned, and implemented 5 improvements (e.g., enhanced backup power, improved communication protocols, updated BCPs)"
- Systematic review process in place
- Majority of significant events reviewed
- Lessons learned documented
- Some improvements implemented

**Score 4**: Comprehensive reviews for ≥80% significant events; documented improvements; implementation tracking; continuous improvement.
- Example: "We have a comprehensive post-event review process, reviewed 85% of significant disruptions in past 3 years, documented lessons learned and improvement actions, tracked implementation (10 improvements implemented, 90% completion rate), and integrated lessons into BCPs, emergency protocols, and training"
- Comprehensive review process
- Most significant events reviewed
- Improvements tracked and implemented
- Integration into plans and procedures

**Score 5**: Group-wide (≥95%) systematic reviews with documented lessons learned, implemented improvements, knowledge management, and integration into continuous improvement.
- Example: "We systematically review 100% of significant disruptions group-wide, document lessons learned in a centralized knowledge management system, track improvement implementation with accountability, integrate lessons into all relevant plans and procedures, and conduct annual reviews of the improvement process itself to ensure effectiveness"
- All significant events reviewed
- Centralized knowledge management
- Strong implementation tracking and accountability
- Integration into organizational learning
- Meta-review of improvement process

**Note**: Review processes that explicitly focus on physical climate events demonstrate higher relevance, but this is not mandatory if the processes systematically review major disruptions including those caused by physical climate events.

---

## CATEGORY 5: SUPPLY CHAIN MANAGEMENT

### M27 - Supplier risk assessment & mapping

**Standard Name**: `Supplier risk assessment & mapping`

**Expanded Definition**:
Assessment and mapping of **physical climate risks across the supply chain**, including:
- Supplier exposure to physical climate hazards
- Supplier criticality classification
- Geographic mapping of supplier locations
- Update frequency

This measure assesses whether the company understands physical climate risks **in its supply chain** (not just its own operations).

**What MUST be present for high scores**:
- ✅ **Supplier risk assessment** conducted
- ✅ **Multiple hazards** assessed (≥3 for score 3, ≥5 for score 4)
- ✅ **Geospatial mapping** (for score 4-5)
- ✅ **Broad coverage** (≥50% by spend for score 3, ≥80% for score 4, ≥95% for score 5)
- ✅ **Regular updates** (annual minimum)

**What does NOT qualify**:
- ❌ Only own operations assessed (not supply chain)
- ❌ Generic "supplier risk" without physical climate specificity
- ❌ No criticality classification
- ❌ Ad hoc assessment without regular updates

**Scoring Criteria**:

**Score 0**: No supplier risk assessment for physical climate risks.

**Score 1**: Generic mention of supply chain risks without physical climate specificity.
- Example: "We assess supply chain risks"

**Score 2**: Assessment for ≥1 hazard; <50% suppliers (by spend).
- Example: "We assessed flood risk for key suppliers"

**Score 3**: Multi-hazard assessment (≥3 hazards); ≥50% suppliers; criticality classification; annual updates.
- Example: "We assess supplier exposure to floods, storms, and heat for 60% of suppliers by spend, with criticality classification, updated annually"

**Score 4**: Comprehensive assessment (≥5 hazards); ≥80% suppliers; geospatial mapping; ≥2x/year updates.
- Example: "We use geospatial tools to assess supplier exposure to floods, storms, heat, wildfires, and droughts for 85% of suppliers by spend, with criticality classification and geographic concentration analysis, updated semi-annually"

**Score 5**: Group-wide (≥95%) multi-hazard supply chain assessment with geospatial mapping, criticality classification, and integration into procurement.
- Example: "We conduct comprehensive supply chain risk assessment for 10+ hazards covering 100% of suppliers by spend with geospatial mapping, criticality classification (Tier 1/2/3), multi-tier supplier assessment, and integration into procurement and supplier selection"

---

### M28 - Supplier diversification & redundancy

**Standard Name**: `Supplier diversification & redundancy`

**Expanded Definition**:
Strategies to **diversify suppliers and build redundancy** to reduce supply chain vulnerability to physical climate risks, including:
- Diversification strategy documented
- Redundancy levels (single, dual, multiple sourcing)
- Coverage of critical suppliers
- Implementation status

This measure assesses whether the company has **multiple suppliers** to reduce dependence on any single supplier that might be disrupted by physical climate events.

**What MUST be present for high scores**:
- ✅ **Diversification strategy** documented
- ✅ **Redundancy levels** defined (e.g., dual sourcing for critical materials)
- ✅ **Critical suppliers covered** (≥50% for score 3, ≥80% for score 4, ≥95% for score 5)
- ✅ **Implementation status** tracked

**What does NOT qualify**:
- ❌ Generic "supplier diversity" without climate risk basis
- ❌ No documented strategy
- ❌ No redundancy for critical suppliers
- ❌ Ad hoc diversification without systematic approach

**Scoring Criteria**:

**Score 0**: No supplier diversification or redundancy strategy.

**Score 1**: Generic mention of diversification without climate risk basis.
- Example: "We diversify our supplier base"

**Score 2**: Some diversification; <50% critical suppliers; ad hoc implementation.
- Example: "We have dual sourcing for some critical materials"

**Score 3**: Systematic diversification; ≥50% critical suppliers; documented strategy.
- Example: "We have a systematic supplier diversification strategy with dual sourcing for 60% of critical suppliers, documented in procurement policy"

**Score 4**: Comprehensive diversification; ≥80% critical suppliers; dual/multiple sourcing; implementation tracking.
- Example: "We have comprehensive supplier diversification with dual or multiple sourcing for 85% of critical suppliers, geographic distribution to reduce concentration risk, and implementation tracking"

**Score 5**: Group-wide (≥95%) diversification with multiple sourcing, geographic distribution, and integration into procurement.
- Example: "We have group-wide supplier diversification with multiple sourcing for 100% of critical suppliers, geographic distribution across multiple regions to reduce concentration risk, and integration into procurement and supplier selection"

---

### M29 - Contractual protections & SLAs

**Standard Name**: `Contractual protections & SLAs`

**Expanded Definition**:
Contractual protections and **service level agreements (SLAs)** with suppliers addressing physical climate risk and business continuity, including:
- Contractual clauses on climate risk management
- SLAs on delivery continuity during disruptions
- Enforcement mechanisms
- Update frequency

This measure assesses whether the company has **contractual protections** to ensure supplier performance during physical climate events.

**What MUST be present for high scores**:
- ✅ **Contractual protections** in place
- ✅ **SLAs** with climate risk metrics
- ✅ **Enforcement mechanisms** documented
- ✅ **Broad coverage** (≥50% of contracts for score 3, ≥80% for score 4, ≥95% for score 5)
- ✅ **Regular contract reviews** (annual minimum)

**What does NOT qualify**:
- ❌ Generic "supplier contracts" without climate risk clauses
- ❌ No SLAs on delivery continuity
- ❌ No enforcement mechanisms
- ❌ Limited coverage (<50% of contracts)

**Scoring Criteria**:

**Score 0**: No contractual protections for physical climate risk.

**Score 1**: Generic mention of supplier contracts without climate risk specificity.
- Example: "We have supplier contracts"

**Score 2**: Protections in <50% contracts; limited SLAs.
- Example: "Some supplier contracts include business continuity clauses"

**Score 3**: Protections in ≥50% contracts; documented SLAs; annual reviews.
- Example: "60% of supplier contracts include physical climate risk clauses and SLAs on delivery continuity, reviewed annually"

**Score 4**: Protections in ≥80% contracts; comprehensive SLAs; enforcement mechanisms; ≥2x/year reviews.
- Example: "85% of supplier contracts include comprehensive physical climate risk clauses and SLAs with enforcement mechanisms (e.g., penalties for non-performance), reviewed semi-annually"

**Score 5**: Group-wide (≥95%) contractual protections with comprehensive SLAs, enforcement mechanisms, and integration into procurement.
- Example: "100% of supplier contracts include comprehensive physical climate risk clauses and SLAs with enforcement mechanisms, integrated into procurement and supplier performance management"

---

### M30 - Inventory management & buffer stocks

**Standard Name**: `Inventory management & buffer stocks`

**Expanded Definition**:
Inventory management strategies and **buffer stocks** to mitigate supply chain disruptions from physical climate events, including:
- Buffer stock policy documented
- Critical materials covered
- Inventory days for critical materials
- Update frequency

This measure assesses whether the company maintains **extra inventory** to buffer against supply chain disruptions from physical climate events.

**What MUST be present for high scores**:
- ✅ **Buffer stock policy** documented
- ✅ **Critical materials covered** (≥50% for score 3, ≥80% for score 4, ≥95% for score 5)
- ✅ **Inventory days** quantified (e.g., "30 days of safety stock")
- ✅ **Regular policy reviews** (annual minimum)

**What does NOT qualify**:
- ❌ Generic "inventory management" without climate risk basis
- ❌ No buffer stock policy
- ❌ No quantified inventory days
- ❌ Limited coverage (<50% of critical materials)

**Scoring Criteria**:

**Score 0**: No inventory management strategy for physical climate risk.

**Score 1**: Generic mention of inventory without climate risk basis.
- Example: "We manage inventory levels"

**Score 2**: Some buffer stocks; <50% critical materials; ad hoc management.
- Example: "We maintain safety stock for some materials"

**Score 3**: Systematic buffer stocks; ≥50% critical materials; documented policy; annual reviews.
- Example: "We maintain buffer stocks for 60% of critical materials (e.g., 30 days safety stock), documented in inventory policy, reviewed annually"

**Score 4**: Comprehensive buffer stocks; ≥80% critical materials; quantified inventory days; ≥2x/year reviews.
- Example: "We maintain comprehensive buffer stocks for 85% of critical materials with quantified inventory days (30-90 days depending on criticality and lead time), reviewed semi-annually"

**Score 5**: Group-wide (≥95%) inventory management with optimized buffer stocks, real-time monitoring, and integration into operations.
- Example: "We have group-wide inventory management with optimized buffer stocks for 100% of critical materials, real-time monitoring of inventory levels, and integration into operations and supply chain planning"

---

### M31 - Logistics & transportation resilience

**Standard Name**: `Logistics & transportation resilience`

**Expanded Definition**:
Resilience of **logistics and transportation networks** to physical climate hazards, including:
- Alternative routes identified
- Multiple transportation modes available
- Contingency plans documented
- Testing frequency

This measure assesses whether the company can **transport goods** even when primary routes are disrupted by physical climate events.

**What MUST be present for high scores**:
- ✅ **Alternative routes** identified
- ✅ **Multiple transportation modes** available (≥2 for score 3, ≥3 for score 4)
- ✅ **Contingency plans** documented
- ✅ **Critical shipments covered** (≥50% for score 3, ≥80% for score 4, ≥95% for score 5)
- ✅ **Regular testing** (annual minimum)

**What does NOT qualify**:
- ❌ Generic "logistics management" without climate risk basis
- ❌ No alternative routes or modes
- ❌ No contingency plans
- ❌ Limited coverage (<50% of critical shipments)

**Scoring Criteria**:

**Score 0**: No logistics resilience measures for physical climate risk.

**Score 1**: Generic mention of logistics without climate risk basis.
- Example: "We manage logistics and transportation"

**Score 2**: Some alternative routes; <50% critical shipments; ad hoc planning.
- Example: "We have identified alternative routes for some key shipments"

**Score 3**: Systematic alternative routes; ≥50% critical shipments; documented contingency plans; annual testing.
- Example: "We have identified alternative routes and transportation modes for 60% of critical shipments, documented in contingency plans, tested annually"

**Score 4**: Comprehensive alternative routes; ≥80% critical shipments; multiple transportation modes; ≥2x/year testing.
- Example: "We have comprehensive alternative routes and multiple transportation modes (road, rail, sea, air) for 85% of critical shipments, documented contingency plans, tested semi-annually"

**Score 5**: Group-wide (≥95%) logistics resilience with multiple routes/modes, real-time monitoring, and integration into operations.
- Example: "We have group-wide logistics resilience with multiple alternative routes and transportation modes for 100% of critical shipments, real-time monitoring of route disruptions, and integration into operations and supply chain planning"

---

## CATEGORY 6: INSURANCE & RISK TRANSFER

### M32 - Insurance coverage adequacy

**Standard Name**: `Insurance coverage adequacy`

**Expanded Definition**:
Adequacy of **insurance coverage** for physical climate risks, including:
- Coverage types (property, business interruption, supply chain, etc.)
- Coverage limits
- Deductibles
- Coverage gaps identified

This measure assesses whether the company has **adequate insurance** to cover potential losses from physical climate events.

**What MUST be present for high scores**:
- ✅ **Multiple coverage types** (≥3 for score 3, ≥5 for score 4)
- ✅ **Coverage limits** disclosed (dollar amounts)
- ✅ **Deductibles** disclosed
- ✅ **Coverage gaps** identified and addressed
- ✅ **Broad coverage** (≥50% of assets for score 3, ≥80% for score 4, ≥95% for score 5)

**What does NOT qualify**:
- ❌ Generic "insurance" without physical climate risk specificity
- ❌ No coverage limits or deductibles disclosed
- ❌ No coverage gap analysis
- ❌ Limited coverage (<50% of assets)

**Scoring Criteria**:

**Score 0**: No insurance coverage or disclosure for physical climate risks.

**Score 1**: Generic mention of insurance without specifics.
- Example: "We have insurance coverage"

**Score 2**: Some coverage; <50% assets; significant gaps.
- Example: "We have property insurance for key facilities"

**Score 3**: Comprehensive coverage; ≥50% assets; ≥3 coverage types; documented limits.
- Example: "We have comprehensive insurance coverage for 60% of assets including property damage ($500M limit), business interruption ($100M limit), and supply chain disruption ($50M limit)"

**Score 4**: Extensive coverage; ≥80% assets; ≥5 coverage types; minimal gaps; regular reviews.
- Example: "We have extensive insurance coverage for 85% of assets including property damage, business interruption, supply chain disruption, flood, and windstorm coverage, with minimal gaps, reviewed annually"

**Score 5**: Group-wide (≥95%) comprehensive coverage with multiple types, adequate limits, minimal gaps, and annual reviews.
- Example: "We have group-wide comprehensive insurance coverage for 100% of assets with multiple coverage types, adequate limits based on risk modeling, minimal gaps, and annual reviews to ensure adequacy"

---

### M33 - Parametric insurance & innovative products

**Standard Name**: `Parametric insurance & innovative products`

**Expanded Definition**:
Use of **parametric insurance** and other innovative risk transfer products for physical climate risks, including:
- Parametric products used (number and types)
- Coverage amounts
- Trigger events defined
- Payout history

This measure assesses whether the company uses **innovative insurance products** that pay out based on predefined triggers (e.g., wind speed, rainfall) rather than traditional indemnity insurance.

**What MUST be present for high scores**:
- ✅ **Parametric products** used
- ✅ **Coverage amounts** disclosed
- ✅ **Trigger events** defined (e.g., "wind speed >150 mph", "rainfall >10 inches in 24 hours")
- ✅ **Broad coverage** (≥50% of assets for score 3, ≥80% for score 4, ≥95% for score 5)
- ✅ **Payout history** (evidence of actual use)

**What does NOT qualify**:
- ❌ Only traditional indemnity insurance (not parametric)
- ❌ Generic "innovative insurance" without specifics
- ❌ No trigger events defined
- ❌ Limited coverage (<50% of assets)

**Scoring Criteria**:

**Score 0**: No parametric insurance or innovative products.

**Score 1**: Generic mention of innovative products without specifics.
- Example: "We explore innovative insurance solutions"

**Score 2**: ≥1 parametric product; <50% assets.
- Example: "We have parametric hurricane insurance for coastal facilities"

**Score 3**: ≥2 parametric products; ≥50% assets; documented triggers.
- Example: "We have parametric insurance for hurricanes (wind speed >150 mph) and floods (rainfall >10 inches in 24 hours) covering 60% of assets"

**Score 4**: ≥3 parametric products; ≥80% assets; multiple triggers; payout history.
- Example: "We have parametric insurance for hurricanes, floods, and earthquakes covering 85% of assets with multiple triggers, and have received payouts 3 times in past 5 years"

**Score 5**: Group-wide (≥95%) parametric insurance with multiple products, comprehensive triggers, and integration into risk management.
- Example: "We have group-wide parametric insurance for multiple hazards covering 100% of assets with comprehensive triggers, payout history, and integration into risk management and financial planning"

---

### M34 - Captives & alternative risk transfer

**Standard Name**: `Captives & alternative risk transfer`

**Expanded Definition**:
Use of **captive insurance companies** or other alternative risk transfer mechanisms for physical climate risks, including:
- Captive insurance used
- Captive coverage amounts
- Alternative mechanisms used (e.g., cat bonds, ILS)
- Risk retention levels

This measure assesses whether the company uses **alternative risk transfer** mechanisms beyond traditional insurance.

**What MUST be present for high scores**:
- ✅ **Captive insurance** or alternative mechanisms used
- ✅ **Coverage amounts** disclosed
- ✅ **Risk retention levels** defined
- ✅ **Broad coverage** (≥50% of assets for score 3, ≥80% for score 4, ≥95% for score 5)

**What does NOT qualify**:
- ❌ Only traditional insurance (not captive or alternative)
- ❌ Generic "risk transfer" without specifics
- ❌ No coverage amounts or retention levels disclosed
- ❌ Limited coverage (<50% of assets)

**Scoring Criteria**:

**Score 0**: No captives or alternative risk transfer.

**Score 1**: Generic mention of alternative mechanisms without specifics.
- Example: "We use alternative risk transfer"

**Score 2**: ≥1 mechanism; <50% assets.
- Example: "We have a captive insurance company for some risks"

**Score 3**: ≥2 mechanisms; ≥50% assets; documented retention levels.
- Example: "We have a captive insurance company and use cat bonds for hurricane risk, covering 60% of assets, with documented risk retention levels"

**Score 4**: Comprehensive mechanisms; ≥80% assets; captive insurance; optimized retention.
- Example: "We have a captive insurance company, cat bonds, and ILS for multiple hazards, covering 85% of assets, with optimized risk retention based on risk modeling"

**Score 5**: Group-wide (≥95%) alternative risk transfer with captive insurance, multiple mechanisms, and integration into risk management.
- Example: "We have a group-wide captive insurance company and multiple alternative risk transfer mechanisms (cat bonds, ILS, reinsurance) for all major hazards, covering 100% of assets, with optimized risk retention and integration into risk management"

---

### M35 - Claims management & recovery

**Standard Name**: `Claims management & recovery`

**Expanded Definition**:
Processes for **managing insurance claims** and recovering from physical climate events, including:
- Claims process documented
- Claims filed (number in past 3 years)
- Recovery rate (percentage of losses recovered)
- Process improvements implemented

This measure assesses whether the company has **effective processes** for filing insurance claims and recovering losses after physical climate events.

**What MUST be present for high scores**:
- ✅ **Claims process** documented
- ✅ **Claims filed** (evidence of actual use)
- ✅ **Recovery rate** disclosed (percentage of losses recovered)
- ✅ **Process improvements** implemented based on experience

**What does NOT qualify**:
- ❌ Generic "claims management" without physical climate specificity
- ❌ No documented process
- ❌ No recovery rate disclosed
- ❌ No process improvements

**Scoring Criteria**:

**Score 0**: No claims management process for physical climate events.

**Score 1**: Generic mention of claims without specifics.
- Example: "We file insurance claims when needed"

**Score 2**: Ad hoc claims management; <50% recovery; limited documentation.
- Example: "We filed 3 claims for flood damage in past 3 years"

**Score 3**: Systematic claims management; ≥50% recovery; documented process.
- Example: "We have a systematic claims management process, filed 5 claims in past 3 years, with 60% average recovery rate"

**Score 4**: Comprehensive claims management; ≥80% recovery; process improvements; tracking.
- Example: "We have comprehensive claims management with documented process, filed 10 claims in past 3 years, with 85% average recovery rate, and implemented 3 process improvements"

**Score 5**: Group-wide (≥95%) claims management with high recovery rates, documented improvements, and integration into risk management.
- Example: "We have group-wide claims management with documented process, filed 15+ claims in past 3 years, with 95% average recovery rate, continuous process improvements, and integration into risk management and insurance strategy"

---

## CATEGORY 7: DATA QUALITY & ASSURANCE

### M36 - Data governance & quality

**Standard Name**: `Data governance & quality`

**Expanded Definition**:
Governance and quality assurance processes for **physical climate risk data**, including:
- Data governance framework documented
- Quality metrics defined
- Validation processes
- Update frequency

This measure assesses whether the company has **robust processes** for ensuring the quality and accuracy of physical climate risk data.

**What MUST be present for high scores**:
- ✅ **Data governance framework** documented
- ✅ **Quality metrics** defined (≥2 for score 3, ≥4 for score 4)
- ✅ **Validation processes** documented
- ✅ **Broad coverage** (≥50% of data for score 3, ≥80% for score 4, ≥95% for score 5)
- ✅ **Regular updates** (annual minimum)

**What does NOT qualify**:
- ❌ Generic "data management" without physical climate risk specificity
- ❌ No documented governance framework
- ❌ No quality metrics or validation
- ❌ Limited coverage (<50% of data)

**Scoring Criteria**:

**Score 0**: No data governance for physical climate risk data.

**Score 1**: Generic mention of data quality without specifics.
- Example: "We ensure data quality"

**Score 2**: Some governance; <50% data; ad hoc validation.
- Example: "We validate physical climate risk data for key facilities"

**Score 3**: Systematic governance; ≥50% data; documented validation; annual updates.
- Example: "We have a data governance framework for physical climate risk data covering 60% of operations, with documented validation processes and quality metrics, updated annually"

**Score 4**: Comprehensive governance; ≥80% data; quality metrics; ≥2x/year updates.
- Example: "We have comprehensive data governance for physical climate risk data covering 85% of operations, with quality metrics (accuracy, completeness, timeliness, consistency), documented validation, updated semi-annually"

**Score 5**: Group-wide (≥95%) data governance with comprehensive quality metrics, automated validation, and integration into operations.
- Example: "We have group-wide data governance for physical climate risk data covering 100% of operations, with comprehensive quality metrics, automated validation processes, and integration into operations and risk management"

---

### M37 - External assurance & verification

**Standard Name**: `External assurance & verification`

**Expanded Definition**:
External assurance or verification of **physical climate risk data and disclosures** by third-party auditors or experts, including:
- Assurance provider named
- Assurance scope (limited vs. reasonable)
- Assurance frequency
- Public disclosure of assurance report

This measure assesses whether the company obtains **independent verification** of its physical climate risk data and disclosures.

**What MUST be present for high scores**:
- ✅ **Assurance provider** named
- ✅ **Assurance scope** defined (limited or reasonable assurance)
- ✅ **Regular assurance** (annual minimum for score 3, ≥2x/year for score 4)
- ✅ **Broad coverage** (≥50% of data for score 3, ≥80% for score 4, ≥95% for score 5)
- ✅ **Public disclosure** of assurance report

**What does NOT qualify**:
- ❌ Only internal audit (not external assurance)
- ❌ Generic "assurance" without physical climate risk specificity
- ❌ No named assurance provider
- ❌ No public disclosure of assurance report

**Scoring Criteria**:

**Score 0**: No external assurance for physical climate risk data.

**Score 1**: Generic mention of assurance without specifics.
- Example: "We seek external assurance"

**Score 2**: Limited assurance; <50% data; ad hoc.
- Example: "We obtained limited assurance over some physical climate risk data in 2023"

**Score 3**: Systematic assurance; ≥50% data; annual; named provider.
- Example: "We obtain annual limited assurance from XYZ Assurance over physical climate risk data covering 60% of operations"

**Score 4**: Comprehensive assurance; ≥80% data; ≥2x/year; reasonable assurance; public disclosure.
- Example: "We obtain semi-annual reasonable assurance from ABC Auditors over physical climate risk data covering 85% of operations, with public disclosure of assurance report"

**Score 5**: Group-wide (≥95%) external assurance with reasonable assurance, public disclosure, and integration into governance.
- Example: "We obtain annual reasonable assurance from a Big 4 auditor over physical climate risk data covering 100% of operations, with public disclosure of assurance report and integration into governance and risk management"

---

## CATEGORY 8: WORKFORCE & COMMUNITY

### M38 - Employee safety & well-being

**Standard Name**: `Employee safety & well-being`

**Expanded Definition**:
Programs and policies to protect **employee safety and well-being** during physical climate events, including:
- Safety programs (number and types)
- Training frequency
- Safety equipment provided
- Support services (number and types)

This measure assesses whether the company protects its **employees** during physical climate events.

**What MUST be present for high scores**:
- ✅ **Safety programs** in place (≥2 for score 3, ≥3 for score 4)
- ✅ **Regular training** (annual minimum for score 3, ≥2x/year for score 4)
- ✅ **Safety equipment** provided
- ✅ **Support services** available (e.g., mental health, financial assistance)
- ✅ **Broad coverage** (≥50% of employees for score 3, ≥80% for score 4, ≥95% for score 5)

**What does NOT qualify**:
- ❌ Generic "employee safety" without physical climate specificity
- ❌ Only general occupational health and safety (not climate-specific)
- ❌ No training or equipment
- ❌ Limited coverage (<50% of employees)

**Scoring Criteria**:

**Score 0**: No employee safety programs for physical climate events.

**Score 1**: Generic mention of safety without physical climate specificity.
- Example: "We ensure employee safety"

**Score 2**: Some programs; <50% employees; ad hoc training.
- Example: "We provide heat stress training for outdoor workers"

**Score 3**: Systematic programs; ≥50% employees; annual training; equipment provided.
- Example: "We have employee safety programs for heat stress, floods, and storms, covering 60% of employees, with annual training and safety equipment (e.g., PPE, emergency kits)"

**Score 4**: Comprehensive programs; ≥80% employees; ≥2x/year training; multiple support services.
- Example: "We have comprehensive employee safety programs for multiple hazards, covering 85% of employees, with semi-annual training, safety equipment, and support services (mental health, financial assistance, relocation support)"

**Score 5**: Group-wide (≥95%) employee safety programs with comprehensive training, equipment, support services, and integration into operations.
- Example: "We have group-wide employee safety programs for all major hazards, covering 100% of employees, with comprehensive training, safety equipment, multiple support services, and integration into operations and emergency response"

---

### M39 - Community engagement & support

**Standard Name**: `Community engagement & support`

**Expanded Definition**:
Engagement with and support for **communities affected by physical climate events**, including:
- Engagement programs (number and types)
- Investment in community support (dollar amounts)
- Community partnerships (number)
- Assistance provided during events

This measure assesses whether the company supports **communities** affected by physical climate events (not just its own operations and employees).

**What MUST be present for high scores**:
- ✅ **Engagement programs** in place (≥2 for score 3, ≥3 for score 4)
- ✅ **Quantified investment** in community support
- ✅ **Community partnerships** (≥2 for score 3, ≥3 for score 4)
- ✅ **Assistance provided** during events (evidence of actual support)
- ✅ **Broad coverage** (≥50% of communities for score 3, ≥80% for score 4, ≥95% for score 5)

**What does NOT qualify**:
- ❌ Generic "community engagement" without physical climate specificity
- ❌ Only general CSR or philanthropy (not climate-specific)
- ❌ No quantified investment or partnerships
- ❌ Limited coverage (<50% of communities)

**Scoring Criteria**:

**Score 0**: No community engagement on physical climate risks.

**Score 1**: Generic mention of community support without physical climate specificity.
- Example: "We support local communities"

**Score 2**: Some engagement; <50% communities; ad hoc support.
- Example: "We provided disaster relief after the 2023 hurricane"

**Score 3**: Systematic engagement; ≥50% communities; documented programs; some investment.
- Example: "We have community engagement programs on physical climate risks for 60% of communities where we operate, with $1M annual investment and 3 community partnerships"

**Score 4**: Comprehensive engagement; ≥80% communities; quantified investment; multiple partnerships.
- Example: "We have comprehensive community engagement on physical climate risks for 85% of communities, with $5M annual investment, 5+ community partnerships, and documented assistance during events"

**Score 5**: Group-wide (≥95%) community engagement with comprehensive programs, significant investment, and integration into operations.
- Example: "We have group-wide community engagement on physical climate risks for 100% of communities, with $10M+ annual investment, 10+ community partnerships, comprehensive assistance programs, and integration into operations and emergency response"

---

### M40 - Just transition & equity considerations

**Standard Name**: `Just transition & equity considerations`

**Expanded Definition**:
Consideration of **just transition principles and equity** in physical climate adaptation, including:
- Just transition policy documented
- Equity considerations integrated
- Vulnerable groups supported (number)
- Support programs (number and types)

This measure assesses whether the company considers **equity and justice** in its physical climate adaptation efforts (not just efficiency and cost-effectiveness).

**What MUST be present for high scores**:
- ✅ **Just transition policy** documented
- ✅ **Equity considerations** integrated into adaptation planning
- ✅ **Vulnerable groups** identified and supported (≥2 for score 3, ≥3 for score 4)
- ✅ **Support programs** in place (≥2 for score 3, ≥3 for score 4)

**What does NOT qualify**:
- ❌ Generic "equity" or "diversity" without physical climate adaptation specificity
- ❌ No documented policy
- ❌ No support for vulnerable groups
- ❌ Ad hoc considerations without systematic approach

**Scoring Criteria**:

**Score 0**: No just transition or equity considerations in physical climate adaptation.

**Score 1**: Generic mention of equity without physical climate specificity.
- Example: "We value equity and inclusion"

**Score 2**: Some considerations; <50% vulnerable groups; ad hoc support.
- Example: "We consider impacts on low-income communities in adaptation planning"

**Score 3**: Systematic considerations; ≥50% vulnerable groups; documented policy.
- Example: "We have a just transition policy for physical climate adaptation, with equity considerations integrated into planning, supporting 60% of identified vulnerable groups (e.g., low-income workers, frontline communities)"

**Score 4**: Comprehensive considerations; ≥80% vulnerable groups; multiple support programs; integration into strategy.
- Example: "We have comprehensive just transition and equity considerations in physical climate adaptation, supporting 85% of vulnerable groups with multiple programs (job training, relocation assistance, community resilience grants), integrated into strategy"

**Score 5**: Group-wide (≥95%) just transition with comprehensive equity considerations, support programs, and integration into all adaptation planning.
- Example: "We have group-wide just transition principles with comprehensive equity considerations integrated into all physical climate adaptation planning, supporting 100% of vulnerable groups with multiple programs, and integration into strategy and decision-making"

---

## CATEGORY 9: KPIs & OUTCOMES

### M41 - Downtime & disruption metrics

**Standard Name**: `Downtime & disruption metrics`

**Expanded Definition**:
Tracking and reporting of **downtime and operational disruptions** caused by physical climate events, including:
- Downtime tracked (yes/no)
- Metrics reported (number)
- Average downtime (hours or days)
- Trend analysis conducted

This measure assesses whether the company **tracks and reports** operational disruptions from physical climate events.

**What MUST be present for high scores**:
- ✅ **Downtime tracked** systematically
- ✅ **Multiple metrics** reported (≥2 for score 3, ≥4 for score 4)
- ✅ **Quantified downtime** (hours or days)
- ✅ **Trend analysis** conducted
- ✅ **Broad coverage** (≥50% of operations for score 3, ≥80% for score 4, ≥95% for score 5)

**What does NOT qualify**:
- ❌ Generic "operational metrics" without physical climate specificity
- ❌ No systematic tracking
- ❌ No quantified downtime
- ❌ Limited coverage (<50% of operations)

**Scoring Criteria**:

**Score 0**: No downtime tracking for physical climate events.

**Score 1**: Generic mention of disruptions without tracking.
- Example: "Physical climate events can cause disruptions"

**Score 2**: Some tracking; <50% operations; limited metrics.
- Example: "We track downtime for key facilities affected by hurricanes"

**Score 3**: Systematic tracking; ≥50% operations; ≥2 metrics; annual reporting.
- Example: "We systematically track downtime and disruptions from physical climate events for 60% of operations, reporting 2 metrics (total downtime hours, number of disruptions) annually"

**Score 4**: Comprehensive tracking; ≥80% operations; ≥4 metrics; trend analysis; ≥2x/year reporting.
- Example: "We comprehensively track downtime and disruptions from physical climate events for 85% of operations, reporting 4 metrics (total downtime, average downtime per event, number of disruptions, revenue impact), with trend analysis, semi-annually"

**Score 5**: Group-wide (≥95%) downtime tracking with comprehensive metrics, trend analysis, and integration into performance management.
- Example: "We track downtime and disruptions from physical climate events for 100% of operations, reporting comprehensive metrics (downtime, disruptions, revenue impact, customer impact), with trend analysis and integration into performance management and KPIs"

---

### M42 - Financial impact tracking

**Standard Name**: `Financial impact tracking`

**Expanded Definition**:
Tracking and reporting of **financial impacts** from physical climate events, including:
- Financial impact tracked (yes/no)
- Impact categories tracked (number)
- Total financial impact (dollar amounts)
- Trend analysis conducted

This measure assesses whether the company **tracks and reports** financial impacts from physical climate events.

**What MUST be present for high scores**:
- ✅ **Financial impact tracked** systematically
- ✅ **Multiple impact categories** tracked (≥2 for score 3, ≥4 for score 4)
- ✅ **Quantified financial impact** (dollar amounts)
- ✅ **Trend analysis** conducted
- ✅ **Broad coverage** (≥50% of operations for score 3, ≥80% for score 4, ≥95% for score 5)

**What does NOT qualify**:
- ❌ Generic "financial metrics" without physical climate specificity
- ❌ No systematic tracking
- ❌ No quantified financial impact
- ❌ Limited coverage (<50% of operations)

**Scoring Criteria**:

**Score 0**: No financial impact tracking for physical climate events.

**Score 1**: Generic mention of financial impacts without tracking.
- Example: "Physical climate events can impact financial performance"

**Score 2**: Some tracking; <50% operations; limited categories.
- Example: "We track damage costs from hurricanes at coastal facilities"

**Score 3**: Systematic tracking; ≥50% operations; ≥2 categories; annual reporting.
- Example: "We systematically track financial impacts from physical climate events for 60% of operations, reporting 2 categories (damage costs, business interruption losses) annually, totaling $10M-$20M per year"

**Score 4**: Comprehensive tracking; ≥80% operations; ≥4 categories; trend analysis; ≥2x/year reporting.
- Example: "We comprehensively track financial impacts from physical climate events for 85% of operations, reporting 4 categories (damage costs, business interruption, supply chain disruption, adaptation costs), with trend analysis, semi-annually, totaling $20M-$50M per year"

**Score 5**: Group-wide (≥95%) financial impact tracking with comprehensive categories, trend analysis, and integration into financial reporting.
- Example: "We track financial impacts from physical climate events for 100% of operations, reporting comprehensive categories (damage, business interruption, supply chain, adaptation, insurance), with trend analysis and integration into financial reporting and investor disclosures"

---

### M43 - Supplier disruption metrics

**Standard Name**: `Supplier disruption metrics`

**Expanded Definition**:
Tracking and reporting of **supplier disruptions** caused by physical climate events, including:
- Disruption tracked (yes/no)
- Metrics reported (number)
- Average disruption duration (days)
- Trend analysis conducted

This measure assesses whether the company **tracks and reports** supplier disruptions from physical climate events.

**What MUST be present for high scores**:
- ✅ **Supplier disruption tracked** systematically
- ✅ **Multiple metrics** reported (≥2 for score 3, ≥4 for score 4)
- ✅ **Quantified disruption** (days or number of disruptions)
- ✅ **Trend analysis** conducted
- ✅ **Broad coverage** (≥50% of suppliers by spend for score 3, ≥80% for score 4, ≥95% for score 5)

**What does NOT qualify**:
- ❌ Generic "supplier metrics" without physical climate specificity
- ❌ No systematic tracking
- ❌ No quantified disruption
- ❌ Limited coverage (<50% of suppliers)

**Scoring Criteria**:

**Score 0**: No supplier disruption tracking for physical climate events.

**Score 1**: Generic mention of supplier disruptions without tracking.
- Example: "Physical climate events can disrupt suppliers"

**Score 2**: Some tracking; <50% suppliers; limited metrics.
- Example: "We track disruptions for key suppliers affected by floods"

**Score 3**: Systematic tracking; ≥50% suppliers; ≥2 metrics; annual reporting.
- Example: "We systematically track supplier disruptions from physical climate events for 60% of suppliers by spend, reporting 2 metrics (number of disruptions, average disruption days) annually"

**Score 4**: Comprehensive tracking; ≥80% suppliers; ≥4 metrics; trend analysis; ≥2x/year reporting.
- Example: "We comprehensively track supplier disruptions from physical climate events for 85% of suppliers by spend, reporting 4 metrics (disruptions, disruption days, financial impact, recovery time), with trend analysis, semi-annually"

**Score 5**: Group-wide (≥95%) supplier disruption tracking with comprehensive metrics, trend analysis, and integration into supply chain management.
- Example: "We track supplier disruptions from physical climate events for 100% of suppliers by spend, reporting comprehensive metrics (disruptions, duration, financial impact, recovery, root cause), with trend analysis and integration into supply chain management and supplier performance"

---

### M44 - Adaptation spend & outcomes

**Standard Name**: `Adaptation spend & outcomes`

**Expanded Definition**:
Tracking and reporting of **adaptation investments and outcomes**, including:
- Adaptation spend tracked (yes/no)
- Annual adaptation spend (dollar amounts)
- Outcomes tracked (number)
- ROI calculated (yes/no)
- Risk reduction quantified (yes/no)

This measure assesses whether the company **tracks and reports** its investments in physical climate adaptation and the outcomes achieved.

**What MUST be present for high scores**:
- ✅ **Adaptation spend tracked** systematically
- ✅ **Quantified annual spend** (dollar amounts)
- ✅ **Multiple outcomes tracked** (≥2 for score 3, ≥4 for score 4)
- ✅ **ROI calculated** (for score 4-5)
- ✅ **Risk reduction quantified** (for score 4-5)
- ✅ **Broad coverage** (≥50% of investments for score 3, ≥80% for score 4, ≥95% for score 5)

**What does NOT qualify**:
- ❌ Generic "capital expenditure" without adaptation specificity
- ❌ No systematic tracking
- ❌ No quantified spend or outcomes
- ❌ Limited coverage (<50% of investments)

**Scoring Criteria**:

**Score 0**: No adaptation spend tracking.

**Score 1**: Generic mention of investments without tracking.
- Example: "We invest in climate resilience"

**Score 2**: Some tracking; <50% investments; limited outcomes.
- Example: "We spent $5M on flood protection in 2023"

**Score 3**: Systematic tracking; ≥50% investments; ≥2 outcomes; annual reporting.
- Example: "We systematically track adaptation spend for 60% of investments, reporting annual spend ($20M) and 2 outcomes (facilities retrofitted, downtime reduction) annually"

**Score 4**: Comprehensive tracking; ≥80% investments; ≥4 outcomes; ROI calculated; ≥2x/year reporting.
- Example: "We comprehensively track adaptation spend for 85% of investments, reporting annual spend ($50M), 4 outcomes (facilities retrofitted, risk reduction, downtime reduction, cost savings), with ROI calculation (3:1 benefit-cost ratio), semi-annually"

**Score 5**: Group-wide (≥95%) adaptation spend tracking with comprehensive outcomes, ROI, risk reduction quantification, and integration into capital planning.
- Example: "We track adaptation spend for 100% of investments, reporting annual spend ($100M+), comprehensive outcomes (risk reduction, downtime, cost savings, co-benefits), ROI (4:1 benefit-cost ratio), risk reduction quantification (50% reduction in exposure), and integration into capital planning and performance management"

---

## END OF EXPANDED DEFINITIONS

**Version**: 2.1  
**Total Measures**: 44  
**Total Categories**: 9  
**Status**: Ready for Review and Editing

---

## USAGE INSTRUCTIONS

1. **Review** these expanded definitions
2. **Edit** any definitions that need refinement
3. **Approve** the final version
4. **Integrate** into the ProcessPrompt Template
5. **Apply** to future assessments

These expanded definitions will ensure that only evidence **specifically addressing physical climate risks** receives high scores, preventing the issue where generic "climate" references score highly without physical risk specificity.



---

## VERIFICATION LOGIC

### Completeness Validation

**Check 1: Measure Count**
```python
if len(measures) != 44:
    raise ValidationError(f"Expected 44 measures, found {len(measures)}")
```

**Check 2: Measure ID Sequence**
```python
expected_ids = [f"M{i:02d}" for i in range(1, 45)]
actual_ids = [m["measure_id"] for m in measures]
if actual_ids != expected_ids:
    raise ValidationError(f"Measure IDs not sequential M01-M44")
```

**Check 3: No Duplicates**
```python
if len(set(actual_ids)) != 44:
    raise ValidationError("Duplicate measure IDs found")
```

### Standardization Validation

**Check 4: Measure Names**
```python
standard_names = {
    "M01": "Board-level physical risk oversight",
    "M02": "Management-level responsibility",
    # ... all 44 standard names
}
for measure in measures:
    if measure["measure_name"] != standard_names[measure["measure_id"]]:
        raise ValidationError(f"Non-standard measure name for {measure['measure_id']}: {measure['measure_name']}")
```

**Check 5: Category Names**
```python
standard_categories = {
    "M01": "Governance & Strategic Oversight",
    "M02": "Governance & Strategic Oversight",
    # ... all 44 standard categories
}
for measure in measures:
    if measure["category"] != standard_categories[measure["measure_id"]]:
        raise ValidationError(f"Non-standard category for {measure['measure_id']}: {measure['category']}")
```

### Scoring Validation

**Check 6: Score Range**
```python
for measure in measures:
    if not (0 <= measure["score"] <= 5):
        raise ValidationError(f"Score out of range for {measure['measure_id']}: {measure['score']}")
```

**Check 7: Score Distribution**
```python
scores = [m["score"] for m in measures]
avg_score = sum(scores) / len(scores)
if avg_score > 4.0:
    raise ValidationWarning("Average score unusually high (>4.0) - review for over-scoring")
if avg_score < 1.5:
    raise ValidationWarning("Average score unusually low (<1.5) - review for under-scoring")
```

### Evidence Validation

**Check 8: Evidence for Non-Zero Scores**
```python
for measure in measures:
    if measure["score"] > 0 and not measure["evidence"]:
        raise ValidationError(f"No evidence for non-zero score: {measure['measure_id']}")
```

**Check 9: Evidence Coverage**
```python
evidence_count = sum(1 for m in measures if m["evidence"])
evidence_coverage = (evidence_count / 44) * 100
if evidence_coverage < 60:
    raise ValidationWarning(f"Evidence coverage low ({evidence_coverage}%) - expected ≥60%")
```

**Check 10: Evidence Duplication**
```python
evidence_list = [m["evidence"] for m in measures if m["evidence"]]
if len(evidence_list) != len(set(evidence_list)):
    raise ValidationWarning("Duplicate evidence found across measures")
```

### Source Validation

**Check 11: Source Documentation**
```python
for measure in measures:
    if measure["evidence"] and not measure["source"]:
        raise ValidationError(f"Evidence without source: {measure['measure_id']}")
```

### Rationale Validation

**Check 12: Rationale Length**
```python
for measure in measures:
    word_count = len(measure["rationale"].split())
    if word_count < 200:
        raise ValidationWarning(f"Rationale too short for {measure['measure_id']}: {word_count} words")
    if word_count > 400:
        raise ValidationWarning(f"Rationale too long for {measure['measure_id']}: {word_count} words")
```

---

## GOVERNANCE TAGS

### Metadata Requirements

Every assessment output MUST include the following governance metadata:

```json
{
  "assessment_date": "YYYY-MM-DD",
  "assessor": "Name or ID",
  "framework_version": "2.0",
  "processprompt_version": "2.2",
  "model_version": "Claude 3.5 Sonnet" // or other model used
}
```

### Version Control

**Framework Version**: 2.0
- 44 measures across 9 categories
- Expanded definitions with precise scoring criteria
- Hazard-agnostic crisis management (M22-M26)

**ProcessPrompt Version**: 2.2
- Integrated expanded definitions
- Mandatory measure name standardization
- Enhanced completeness checks
- Quality validation requirements

### Audit Trail

For each assessment, maintain:
- Source documents accessed (title, URL, date accessed)
- Evidence extraction date
- Assessment completion date
- Validation results (pass/fail for each check)
- Any manual overrides or adjustments (with justification)

---

## QUALITY STANDARDS

### Evidence Quality

**High-Quality Evidence**:
- ✅ Verbatim quotes from primary sources
- ✅ Specific to the measure being assessed
- ✅ Includes quantitative data where available
- ✅ Recent (2023-2025)
- ✅ From authoritative sources (company reports, not news articles)

**Low-Quality Evidence**:
- ❌ Paraphrased or summarized
- ❌ Generic (could apply to any measure)
- ❌ Qualitative only when quantitative is available
- ❌ Outdated (>3 years old)
- ❌ From secondary sources (news, third-party reports)

### Scoring Quality

**Realistic Scoring**:
- Most companies score 2-3 on most measures
- Scores of 4-5 require exceptional evidence
- Scores of 0-1 are common for measures with no/weak evidence
- Average score typically 2.5-3.0 for mature companies

**Over-Scoring Indicators**:
- Average score >4.0
- >50% of measures scored 4-5
- High scores without strong evidence
- Generic evidence counted as high-quality

**Under-Scoring Indicators**:
- Average score <1.5
- >50% of measures scored 0-1
- Strong evidence not recognized
- Overly strict interpretation of criteria

### Consistency Standards

**Measure Names**:
- ✅ 100% match with Standard Reference
- ❌ 0% tolerance for variations

**Category Names**:
- ✅ 100% match with Standard Reference
- ❌ 0% tolerance for variations

**Evidence Format**:
- ✅ Verbatim quotes only
- ✅ Pipe-separated for multiple quotes
- ✅ Source and page number included

---

## COMMON PITFALLS

### Pitfall 1: Generic "Climate" Evidence

**Problem**: Counting generic "climate change" or "climate strategy" as physical risk management.

**Example**:
- Evidence: "We have a comprehensive climate strategy"
- Score: 5 ❌ (Incorrect - too generic)

**Solution**: Require explicit mention of physical climate risks or specific hazards.

**Correct Example**:
- Evidence: "We assess physical climate risks including floods, storms, and heat at all facilities"
- Score: 3-4 ✅ (Correct - specific physical risks)

---

### Pitfall 2: Transition Risk Confusion

**Problem**: Counting emissions reduction, net zero, or decarbonization as physical risk management.

**Example**:
- Evidence: "We have committed to net zero by 2050"
- Score: 4 ❌ (Incorrect - this is transition risk, not physical)

**Solution**: Only count evidence that addresses physical impacts (floods, storms, heat, etc.).

**Correct Example**:
- Evidence: "We have committed to making all facilities resilient to 100-year flood events by 2030"
- Score: 3-4 ✅ (Correct - physical resilience commitment)

---

### Pitfall 3: Measure Name Variations

**Problem**: Creating your own measure names instead of using Standard Reference.

**Example**:
- Measure Name: "Board oversight of climate risks" ❌
- Standard Name: "Board-level physical risk oversight" ✅

**Solution**: Always copy-paste measure names from Standard Reference (Section 7).

---

### Pitfall 4: Evidence Duplication

**Problem**: Using the same evidence quote for multiple measures.

**Example**:
- M01 Evidence: "Board reviews physical climate risks quarterly"
- M02 Evidence: "Board reviews physical climate risks quarterly" ❌ (Same quote)

**Solution**: Find measure-specific evidence for each measure.

**Correct Example**:
- M01 Evidence: "Board Risk Committee oversees physical climate risks"
- M02 Evidence: "Chief Risk Officer is responsible for physical climate risk management"

---

### Pitfall 5: Incomplete Assessments

**Problem**: Skipping measures with no evidence instead of scoring them 0.

**Example**:
- Assessment has 38 measures ❌ (Missing 6 measures)

**Solution**: Assess all 44 measures. If no evidence, score = 0.

**Correct Example**:
- Assessment has 44 measures ✅
- 6 measures scored 0 (no evidence)

---

### Pitfall 6: Paraphrased Evidence

**Problem**: Summarizing or paraphrasing evidence instead of using verbatim quotes.

**Example**:
- Evidence: "The company assesses physical risks at its facilities" ❌ (Paraphrased)

**Solution**: Copy exact text from source documents.

**Correct Example**:
- Evidence: "We conduct comprehensive physical climate risk assessments at 85% of our facilities, covering floods, storms, heat, and wildfires" ✅ (Verbatim)

---

### Pitfall 7: Over-Scoring Crisis Management

**Problem**: Requiring explicit "physical climate" mention for M22-M26 when comprehensive processes are sufficient.

**Example**:
- Evidence: "We have comprehensive business continuity plans covering facility damage, power outages, supply chain disruption, and employee safety, tested quarterly"
- Score: 1 ❌ (Incorrect - this is comprehensive and qualifies)

**Solution**: For M22-M26, comprehensive hazard-agnostic processes qualify even without explicit "physical climate" mention.

**Correct Example**:
- Evidence: "We have comprehensive business continuity plans covering facility damage, power outages, supply chain disruption, and employee safety, tested quarterly"
- Score: 4 ✅ (Correct - comprehensive scope and frequent testing)

---

## CONTINUOUS IMPROVEMENT

### Feedback Loop

After completing assessments, review and improve:

1. **Validation Results**
   - Track validation pass/fail rates
   - Identify common errors
   - Update training or guidance

2. **Evidence Quality**
   - Review evidence coverage rates
   - Identify measures with consistently low evidence
   - Improve document discovery process

3. **Scoring Consistency**
   - Compare scores across assessors
   - Identify scoring drift
   - Calibrate scoring standards

4. **Process Efficiency**
   - Track time per assessment
   - Identify bottlenecks
   - Streamline workflow

### Version Updates

**When to Update ProcessPrompt**:
- New measures added to framework
- Scoring criteria refined based on experience
- New data sources identified
- Common errors identified and addressed

**Version Numbering**:
- Major version (X.0): Framework changes (new measures, categories)
- Minor version (X.Y): ProcessPrompt improvements (definitions, validation)

**Current Version**: 2.2
- Framework 2.0 (44 measures, 9 categories)
- ProcessPrompt 2.2 (expanded definitions, standardization, validation)

---

## APPENDIX: QUICK REFERENCE

### Assessment Checklist

**Phase 1: Document Discovery**
- [ ] SustainabilityReports.com checked
- [ ] Company website checked
- [ ] Web search conducted
- [ ] At least 2 primary sources found
- [ ] Most recent reports (2023-2025)

**Phase 2: Information Gathering**
- [ ] All documents reviewed
- [ ] Evidence extracted for ≥30 measures
- [ ] All evidence verbatim
- [ ] All evidence has source/page
- [ ] Gaps identified

**Phase 3: Measure Assessment**
- [ ] All 44 measures assessed
- [ ] Measure names copied from Standard Reference
- [ ] Category names copied from Standard Reference
- [ ] Expanded definitions consulted
- [ ] Scores 0-5 with rationale
- [ ] Evidence verbatim (if score >0)
- [ ] Source documented

**Phase 4: Validation**
- [ ] Exactly 44 measures
- [ ] Measure IDs M01-M44 sequential
- [ ] No duplicate IDs
- [ ] Measure names match Standard Reference
- [ ] Category names match Standard Reference
- [ ] All scores 0-5
- [ ] Evidence for all scores >0
- [ ] Evidence coverage ≥60%
- [ ] No evidence duplication
- [ ] All evidence has source
- [ ] Rationales 200-400 words
- [ ] Physical risk focus (except M22-M26)

---

## END OF PROCESSPROMPT TEMPLATE v2.2

**This template is ready to use immediately in any new Manus chat or by any analyst to conduct physical climate risk assessments with identical structure, logic, and rigor.**

**For questions or improvements, contact the framework maintainer.**

**Version**: 2.2  
**Date**: November 2025  
**Framework**: 2.0 (44 measures)  
**License**: Internal use only  

